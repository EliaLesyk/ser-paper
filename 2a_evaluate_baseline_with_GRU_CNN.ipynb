{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "388194a4-de8c-4127-8fc5-38bda1f37d93",
   "metadata": {},
   "source": [
    "# Define Baseline with CNN and GRU Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4a7638-5cee-4cfc-8ba8-b7fa2da9a6d6",
   "metadata": {},
   "source": [
    "## Define pre-processing functions to extract Mel Spectrograms and MFCC-s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a097df7e-2984-44d1-9c47-ccb03476764a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in /opt/conda/lib/python3.10/site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.10/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.59.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.3.7)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (4.11.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.0.7)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from lazy-loader>=0.1->librosa) (23.2)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51.0->librosa) (0.42.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.1->librosa) (4.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.1->librosa) (2.31.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c5789112-75f5-43c3-b49e-44f159297c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import wave\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pylab\n",
    "import pandas as pd\n",
    "import scipy.io.wavfile as wav\n",
    "import scipy.signal as sig\n",
    "import skimage.measure\n",
    "import time\n",
    "import os\n",
    "from scipy.io.wavfile import read\n",
    "from sklearn import preprocessing\n",
    "from scipy.fftpack import dct  # Discrete Cosine Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c7b3c928-3d8e-44c1-83c8-373f311a7661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "SPECTR_DUR = 128\n",
    "NUMCEP = 40  # Number of coefficients to extract\n",
    "MFCC_DUR = 50\n",
    "MFCC_STEP = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2cf0da8f-1a52-4664-b366-27443aeaa12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spectrogram(wav_file, view=False):\n",
    "    MAX_SPECTRG_LENGTH = 999  # 8 sec\n",
    "    MAX_SPECTRG_TIME_LENGTH_POOLED = SPECTR_DUR\n",
    "    MAX_SPECTRG_FREQ_LENGTH_POOLED = SPECTR_DUR\n",
    "\n",
    "    def get_wav_info(wav_file):\n",
    "        wav = wave.open(wav_file, 'r')\n",
    "        frames = wav.readframes(-1)\n",
    "        sound_info = np.fromstring(frames, dtype=np.uint16)\n",
    "        frame_rate = wav.getframerate()\n",
    "        wav.close()\n",
    "        return sound_info, frame_rate\n",
    "\n",
    "    frame_rate, sound_info = wav.read(wav_file)\n",
    "    spec, freqs, times, axes = pylab.specgram(sound_info, Fs=frame_rate)\n",
    "    times = times[:MAX_SPECTRG_LENGTH]\n",
    "    spec = spec[:, :MAX_SPECTRG_LENGTH]\n",
    "    spec_log = np.log(spec)\n",
    "    spec_pooled = skimage.measure.block_reduce(spec_log, (1, 8), np.mean)\n",
    "    spec_cropped = spec_pooled[:MAX_SPECTRG_FREQ_LENGTH_POOLED, :MAX_SPECTRG_TIME_LENGTH_POOLED]\n",
    "    spectrogram = np.zeros((MAX_SPECTRG_FREQ_LENGTH_POOLED, MAX_SPECTRG_TIME_LENGTH_POOLED))\n",
    "    spectrogram[:, :spec_cropped.shape[1]] = spec_cropped\n",
    "\n",
    "    if view:\n",
    "        plt.imshow(spec_cropped, cmap='hot', interpolation='nearest')\n",
    "        plt.show()\n",
    "    return spectrogram\n",
    "\n",
    "\n",
    "def generate_mel_spectr(file_audio, view=False):\n",
    "    y, sr = librosa.load(file_audio, sr=16000)\n",
    "    mspectr = librosa.feature.melspectrogram(\n",
    "                            y=y, \n",
    "                            sr=sr, \n",
    "                            n_fft=2048, \n",
    "                            hop_length=int(0.01 * sr),\n",
    "                            win_length=int(0.025 * sr),\n",
    "                            window='hann')\n",
    "    log_mspectr = librosa.power_to_db(mspectr)\n",
    "\n",
    "    if view:\n",
    "        plt.imshow(log_mspectr, cmap='hot', interpolation='nearest')\n",
    "        plt.show()\n",
    "    return log_mspectr\n",
    "\n",
    "\n",
    "def generate_mfcc(file_audio, view=False):\n",
    "    rate, audio_input = read(file_audio)\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    standard_X = np.hstack(scaler.fit_transform(np.vstack(audio_input)))\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "                            y=standard_X,\n",
    "                            sr=rate,    # fs\n",
    "                            n_mfcc=NUMCEP, \n",
    "                            n_fft=2048, \n",
    "                            lifter=2 * NUMCEP)\n",
    "\n",
    "    if view:\n",
    "        fs, sig = wav.read(file_audio)\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        plt.title('MFCC')\n",
    "        plt.imshow(mfcc.T, aspect='auto', extent=[0, len(sig) / fs, 0, 10])\n",
    "        plt.ylabel('Coefficients', fontsize=18)\n",
    "        plt.xlabel('Time [sec]', fontsize=18)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f0713e-26f4-420a-bc5a-e20842eacbb5",
   "metadata": {},
   "source": [
    "## Pre-process AIBO and IEMOCAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "75198b40-412f-4dfb-bc6e-62bd351e2103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "LOCAL_DIR = './data/'\n",
    "save_path = LOCAL_DIR + 'mfcc_msp/'\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8d6de093-ba8b-42a1-a2dd-e168c687ac36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_mfcc = generate_mfcc(os.path.join(LOCAL_DIR, \"IEMOCAP/Session5/Ses05M_script03_2_M043.wav\"), view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "35877187-71a2-47ad-aff5-d0cf7648ee51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 70)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mfcc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b343c898-fd85-4421-bc35-42c39567fc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ICP_CLASS_TO_ID = {\"neu\": 0, \"hap\": 1, \"sad\": 2, \"fru\": 3, \"ang\": 4}\n",
    "ICP_ID_TO_CLASS = {v: k for k, v in ICP_CLASS_TO_ID.items()}\n",
    "\n",
    "AIBO_CLASS_TO_ID = {'A': 0, 'E': 1, 'N': 2, 'P': 3, 'R': 4}\n",
    "AIBO_ID_TO_CLASS = {v: k for k, v in AIBO_CLASS_TO_ID.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b05693a4-bf13-40ac-acfe-493787feefc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets from .pkl\n",
    "with open(os.path.join(LOCAL_DIR, 'adults.pkl'), 'rb') as f:\n",
    "    iemocap_df = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(LOCAL_DIR, 'children.pkl'), 'rb') as f:\n",
    "    aibo_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3f397c4c-322b-4cc2-87c9-b1cc174025d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>emotion</th>\n",
       "      <th>gender</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ses01F_impro01_F000</td>\n",
       "      <td>neu</td>\n",
       "      <td>1</td>\n",
       "      <td>IEMOCAP/Session1/Ses01F_impro01_F000.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ses01F_impro01_F001</td>\n",
       "      <td>neu</td>\n",
       "      <td>1</td>\n",
       "      <td>IEMOCAP/Session1/Ses01F_impro01_F001.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ses01F_impro01_F002</td>\n",
       "      <td>neu</td>\n",
       "      <td>1</td>\n",
       "      <td>IEMOCAP/Session1/Ses01F_impro01_F002.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ses01F_impro01_F005</td>\n",
       "      <td>neu</td>\n",
       "      <td>1</td>\n",
       "      <td>IEMOCAP/Session1/Ses01F_impro01_F005.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ses01F_impro01_F006</td>\n",
       "      <td>fru</td>\n",
       "      <td>1</td>\n",
       "      <td>IEMOCAP/Session1/Ses01F_impro01_F006.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22135</th>\n",
       "      <td>Ses05M_script03_2_M043_with_20dB_noise</td>\n",
       "      <td>ang</td>\n",
       "      <td>0</td>\n",
       "      <td>IEMOCAP/Session5/Ses05M_script03_2_M043_with_2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22136</th>\n",
       "      <td>Ses05M_script03_2_M044_with_10dB_noise</td>\n",
       "      <td>ang</td>\n",
       "      <td>0</td>\n",
       "      <td>IEMOCAP/Session5/Ses05M_script03_2_M044_with_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22137</th>\n",
       "      <td>Ses05M_script03_2_M044_with_20dB_noise</td>\n",
       "      <td>ang</td>\n",
       "      <td>0</td>\n",
       "      <td>IEMOCAP/Session5/Ses05M_script03_2_M044_with_2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22138</th>\n",
       "      <td>Ses05M_script03_2_M045_with_10dB_noise</td>\n",
       "      <td>ang</td>\n",
       "      <td>0</td>\n",
       "      <td>IEMOCAP/Session5/Ses05M_script03_2_M045_with_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22139</th>\n",
       "      <td>Ses05M_script03_2_M045_with_20dB_noise</td>\n",
       "      <td>ang</td>\n",
       "      <td>0</td>\n",
       "      <td>IEMOCAP/Session5/Ses05M_script03_2_M045_with_2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22140 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     filename emotion  gender  \\\n",
       "0                         Ses01F_impro01_F000     neu       1   \n",
       "1                         Ses01F_impro01_F001     neu       1   \n",
       "2                         Ses01F_impro01_F002     neu       1   \n",
       "3                         Ses01F_impro01_F005     neu       1   \n",
       "4                         Ses01F_impro01_F006     fru       1   \n",
       "...                                       ...     ...     ...   \n",
       "22135  Ses05M_script03_2_M043_with_20dB_noise     ang       0   \n",
       "22136  Ses05M_script03_2_M044_with_10dB_noise     ang       0   \n",
       "22137  Ses05M_script03_2_M044_with_20dB_noise     ang       0   \n",
       "22138  Ses05M_script03_2_M045_with_10dB_noise     ang       0   \n",
       "22139  Ses05M_script03_2_M045_with_20dB_noise     ang       0   \n",
       "\n",
       "                                                    path  \n",
       "0               IEMOCAP/Session1/Ses01F_impro01_F000.wav  \n",
       "1               IEMOCAP/Session1/Ses01F_impro01_F001.wav  \n",
       "2               IEMOCAP/Session1/Ses01F_impro01_F002.wav  \n",
       "3               IEMOCAP/Session1/Ses01F_impro01_F005.wav  \n",
       "4               IEMOCAP/Session1/Ses01F_impro01_F006.wav  \n",
       "...                                                  ...  \n",
       "22135  IEMOCAP/Session5/Ses05M_script03_2_M043_with_2...  \n",
       "22136  IEMOCAP/Session5/Ses05M_script03_2_M044_with_1...  \n",
       "22137  IEMOCAP/Session5/Ses05M_script03_2_M044_with_2...  \n",
       "22138  IEMOCAP/Session5/Ses05M_script03_2_M045_with_1...  \n",
       "22139  IEMOCAP/Session5/Ses05M_script03_2_M045_with_2...  \n",
       "\n",
       "[22140 rows x 4 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iemocap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "123822ce-63a9-40f8-aacc-695b736c57c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>emotion</th>\n",
       "      <th>gender</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ses01F_impro01_F000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>IEMOCAP/Session1/Ses01F_impro01_F000.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ses01F_impro01_F001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>IEMOCAP/Session1/Ses01F_impro01_F001.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ses01F_impro01_F002</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>IEMOCAP/Session1/Ses01F_impro01_F002.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ses01F_impro01_F005</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>IEMOCAP/Session1/Ses01F_impro01_F005.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ses01F_impro01_F006</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>IEMOCAP/Session1/Ses01F_impro01_F006.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22135</th>\n",
       "      <td>Ses05M_script03_2_M043_with_20dB_noise</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>IEMOCAP/Session5/Ses05M_script03_2_M043_with_2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22136</th>\n",
       "      <td>Ses05M_script03_2_M044_with_10dB_noise</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>IEMOCAP/Session5/Ses05M_script03_2_M044_with_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22137</th>\n",
       "      <td>Ses05M_script03_2_M044_with_20dB_noise</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>IEMOCAP/Session5/Ses05M_script03_2_M044_with_2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22138</th>\n",
       "      <td>Ses05M_script03_2_M045_with_10dB_noise</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>IEMOCAP/Session5/Ses05M_script03_2_M045_with_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22139</th>\n",
       "      <td>Ses05M_script03_2_M045_with_20dB_noise</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>IEMOCAP/Session5/Ses05M_script03_2_M045_with_2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22140 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     filename  emotion  gender  \\\n",
       "0                         Ses01F_impro01_F000        0       1   \n",
       "1                         Ses01F_impro01_F001        0       1   \n",
       "2                         Ses01F_impro01_F002        0       1   \n",
       "3                         Ses01F_impro01_F005        0       1   \n",
       "4                         Ses01F_impro01_F006        3       1   \n",
       "...                                       ...      ...     ...   \n",
       "22135  Ses05M_script03_2_M043_with_20dB_noise        4       0   \n",
       "22136  Ses05M_script03_2_M044_with_10dB_noise        4       0   \n",
       "22137  Ses05M_script03_2_M044_with_20dB_noise        4       0   \n",
       "22138  Ses05M_script03_2_M045_with_10dB_noise        4       0   \n",
       "22139  Ses05M_script03_2_M045_with_20dB_noise        4       0   \n",
       "\n",
       "                                                    path  \n",
       "0               IEMOCAP/Session1/Ses01F_impro01_F000.wav  \n",
       "1               IEMOCAP/Session1/Ses01F_impro01_F001.wav  \n",
       "2               IEMOCAP/Session1/Ses01F_impro01_F002.wav  \n",
       "3               IEMOCAP/Session1/Ses01F_impro01_F005.wav  \n",
       "4               IEMOCAP/Session1/Ses01F_impro01_F006.wav  \n",
       "...                                                  ...  \n",
       "22135  IEMOCAP/Session5/Ses05M_script03_2_M043_with_2...  \n",
       "22136  IEMOCAP/Session5/Ses05M_script03_2_M044_with_1...  \n",
       "22137  IEMOCAP/Session5/Ses05M_script03_2_M044_with_2...  \n",
       "22138  IEMOCAP/Session5/Ses05M_script03_2_M045_with_1...  \n",
       "22139  IEMOCAP/Session5/Ses05M_script03_2_M045_with_2...  \n",
       "\n",
       "[22140 rows x 4 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the emotion mapping to iemocap_df\n",
    "iemocap_df['emotion'] = iemocap_df['emotion'].map(ICP_CLASS_TO_ID)\n",
    "iemocap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a2760016-f5c3-400d-93b1-72dcc1994c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aibo_df['school'] = aibo_df['filename'].apply(lambda x: x.split('_')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2afdd228-31d6-4b63-8f8a-e3b2c48ba65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>emotion</th>\n",
       "      <th>path</th>\n",
       "      <th>school</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mont_01_000_00</td>\n",
       "      <td>0</td>\n",
       "      <td>AIBO/wav/Mont_01_000_00.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mont_01_001_00</td>\n",
       "      <td>0</td>\n",
       "      <td>AIBO/wav/Mont_01_001_00.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mont_01_001_01</td>\n",
       "      <td>0</td>\n",
       "      <td>AIBO/wav/Mont_01_001_01.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mont_01_004_00</td>\n",
       "      <td>0</td>\n",
       "      <td>AIBO/wav/Mont_01_004_00.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mont_01_005_00</td>\n",
       "      <td>0</td>\n",
       "      <td>AIBO/wav/Mont_01_005_00.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18211</th>\n",
       "      <td>Ohm_32_317_01</td>\n",
       "      <td>0</td>\n",
       "      <td>AIBO/wav/Ohm_32_317_01.wav</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18212</th>\n",
       "      <td>Ohm_32_318_00</td>\n",
       "      <td>3</td>\n",
       "      <td>AIBO/wav/Ohm_32_318_00.wav</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18213</th>\n",
       "      <td>Ohm_32_319_00</td>\n",
       "      <td>3</td>\n",
       "      <td>AIBO/wav/Ohm_32_319_00.wav</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18214</th>\n",
       "      <td>Ohm_32_320_00</td>\n",
       "      <td>0</td>\n",
       "      <td>AIBO/wav/Ohm_32_320_00.wav</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18215</th>\n",
       "      <td>Ohm_32_321_00</td>\n",
       "      <td>2</td>\n",
       "      <td>AIBO/wav/Ohm_32_321_00.wav</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18216 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             filename  emotion                         path  school\n",
       "0      Mont_01_000_00        0  AIBO/wav/Mont_01_000_00.wav       1\n",
       "1      Mont_01_001_00        0  AIBO/wav/Mont_01_001_00.wav       1\n",
       "2      Mont_01_001_01        0  AIBO/wav/Mont_01_001_01.wav       1\n",
       "3      Mont_01_004_00        0  AIBO/wav/Mont_01_004_00.wav       1\n",
       "4      Mont_01_005_00        0  AIBO/wav/Mont_01_005_00.wav       1\n",
       "...               ...      ...                          ...     ...\n",
       "18211   Ohm_32_317_01        0   AIBO/wav/Ohm_32_317_01.wav       2\n",
       "18212   Ohm_32_318_00        3   AIBO/wav/Ohm_32_318_00.wav       2\n",
       "18213   Ohm_32_319_00        3   AIBO/wav/Ohm_32_319_00.wav       2\n",
       "18214   Ohm_32_320_00        0   AIBO/wav/Ohm_32_320_00.wav       2\n",
       "18215   Ohm_32_321_00        2   AIBO/wav/Ohm_32_321_00.wav       2\n",
       "\n",
       "[18216 rows x 4 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the mapping from school names to integers\n",
    "school_mapping = {'Mont': 1, 'Ohm': 2}\n",
    "\n",
    "# Apply the mapping to the 'school' column to convert it to integers\n",
    "aibo_df['school'] = aibo_df['school'].map(school_mapping).astype('int64')\n",
    "aibo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6db591e5-1f96-4408-8357-898892975dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "def process_single_file(row, dataset, mfcc_dur=MFCC_DUR, mfcc_step=MFCC_STEP):\n",
    "    try:\n",
    "        file_path = os.path.join(LOCAL_DIR, row['path'])\n",
    "        attribute_column = 'gender' if dataset == 'IEMOCAP' else 'school'\n",
    "        \n",
    "        # Generate MFCC\n",
    "        mfcc = generate_mfcc(file_path)\n",
    "        mfcc_data = []\n",
    "        if mfcc.shape[1] > mfcc_dur:\n",
    "            mfcc_segments = [mfcc[:, i:i + mfcc_dur] for i in range(0, mfcc.shape[1] - mfcc_dur + 1, mfcc_step)]\n",
    "            for segment in mfcc_segments:\n",
    "                mfcc_data.append({\n",
    "                    'filename': row['filename'],\n",
    "                    'emotion': row['emotion'],\n",
    "                    attribute_column: row[attribute_column],\n",
    "                    'mfcc': segment\n",
    "                })\n",
    "        \n",
    "        # Generate Mel Spectrogram\n",
    "        mel_spectr = generate_mel_spectr(file_path)\n",
    "        mel_spectr_data = []\n",
    "        if mel_spectr.shape[1] > mfcc_dur:\n",
    "            mel_segments = [mel_spectr[:, i:i + mfcc_dur] for i in range(0, mel_spectr.shape[1] - mfcc_dur + 1, mfcc_step)]\n",
    "            for segment in mel_segments:\n",
    "                mel_spectr_data.append({\n",
    "                    'filename': row['filename'],\n",
    "                    'emotion': row['emotion'],\n",
    "                    attribute_column: row[attribute_column],\n",
    "                    'mel_spectr': segment\n",
    "                })\n",
    "        \n",
    "        return mfcc_data, mel_spectr_data, None\n",
    "    except Exception as e:\n",
    "        return [], [], (row['filename'], str(e))\n",
    "\n",
    "\n",
    "def process_audio_features(labels_df, dataset, checkpoint_file='checkpoint.pkl', batch_size=1000, num_processes=None):\n",
    "    if num_processes is None:\n",
    "        num_processes = multiprocessing.cpu_count()\n",
    "    \n",
    "    # Load checkpoint if it exists\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        with open(checkpoint_file, 'rb') as f:\n",
    "            checkpoint = pickle.load(f)\n",
    "        mfcc_data = checkpoint.get('mfcc_data', [])\n",
    "        mel_spectr_data = checkpoint.get('mel_spectr_data', [])\n",
    "        problems = checkpoint.get('problems', [])\n",
    "        start_idx = checkpoint.get('last_processed_idx', -1) + 1\n",
    "        print(f\"Resuming from file index {start_idx}\")\n",
    "    else:\n",
    "        mfcc_data = []\n",
    "        mel_spectr_data = []\n",
    "        problems = []\n",
    "        start_idx = 0\n",
    "\n",
    "    total_files = len(labels_df)\n",
    "    start_time = time.time()\n",
    "\n",
    "    with multiprocessing.Pool(processes=num_processes) as pool:\n",
    "        for idx in range(start_idx, total_files, batch_size):\n",
    "            batch_end = min(idx + batch_size, total_files)\n",
    "            batch_df = labels_df.iloc[idx:batch_end]\n",
    "            \n",
    "            # Use starmap to pass multiple arguments\n",
    "            results = pool.starmap(process_single_file, \n",
    "                                   [(row, dataset) for _, row in batch_df.iterrows()])\n",
    "            \n",
    "            for mfcc_batch, mel_batch, problem in results:\n",
    "                mfcc_data.extend(mfcc_batch)\n",
    "                mel_spectr_data.extend(mel_batch)\n",
    "                if problem:\n",
    "                    problems.append(problem)\n",
    "            \n",
    "            # Progress log and estimation\n",
    "            elapsed_time = time.time() - start_time\n",
    "            processed_files = batch_end - start_idx\n",
    "            avg_time_per_file = elapsed_time / processed_files\n",
    "            remaining_files = total_files - batch_end\n",
    "            estimated_time_left = avg_time_per_file * remaining_files\n",
    "            print(f\"Processed {batch_end}/{total_files} files. Estimated time left: {estimated_time_left // 60:.2f} minutes.\")\n",
    "\n",
    "            # Save checkpoint\n",
    "            checkpoint = {\n",
    "                'mfcc_data': mfcc_data,\n",
    "                'mel_spectr_data': mel_spectr_data,\n",
    "                'problems': problems,\n",
    "                'last_processed_idx': batch_end - 1\n",
    "            }\n",
    "            with open(checkpoint_file, 'wb') as f:\n",
    "                pickle.dump(checkpoint, f)\n",
    "            print(f\"Checkpoint saved at file index {batch_end - 1}\")\n",
    "\n",
    "    print(\"Problems encountered:\", problems)\n",
    "    \n",
    "    mfcc_df = pd.DataFrame(mfcc_data)\n",
    "    mel_spectr_df = pd.DataFrame(mel_spectr_data)\n",
    "    return mfcc_df, mel_spectr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "30b58d61-bdaf-46d9-8444-a045b215750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError, ClientError\n",
    "\n",
    "\n",
    "def file_exists_in_s3(bucket_name, s3_path):\n",
    "    s3 = boto3.client('s3')\n",
    "    try:\n",
    "        s3.head_object(Bucket=bucket_name, Key=s3_path)\n",
    "        return True\n",
    "    except ClientError as e:\n",
    "        if e.response['Error']['Code'] == '404':\n",
    "            return False\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "def upload_to_s3(local_path, bucket_name, s3_path):\n",
    "    s3 = boto3.client('s3')\n",
    "    try:\n",
    "        if file_exists_in_s3(bucket_name, s3_path):\n",
    "            print(f\"File already exists: s3://{bucket_name}/{s3_path}\")\n",
    "            return True\n",
    "        \n",
    "        s3.upload_file(local_path, bucket_name, s3_path)\n",
    "        \n",
    "        # Verify the upload\n",
    "        s3_object = s3.head_object(Bucket=bucket_name, Key=s3_path)\n",
    "        s3_size = s3_object['ContentLength']\n",
    "        local_size = os.path.getsize(local_path)\n",
    "        \n",
    "        if s3_size == local_size:\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Size mismatch for {local_path} and s3://{bucket_name}/{s3_path}\")\n",
    "            return False\n",
    "    except NoCredentialsError:\n",
    "        print(\"Credentials not available\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to upload {local_path} to s3://{bucket_name}/{s3_path}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def upload_features_to_s3(local_dir, bucket_name, dataset):\n",
    "    local_save_path = os.path.join(local_dir, 'mfcc_msp')\n",
    "    \n",
    "    all_files_uploaded = True\n",
    "    \n",
    "    for root, _, files in os.walk(local_save_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.pkl'):\n",
    "                local_file_path = os.path.join(root, file)\n",
    "                s3_file_path = os.path.join(dataset, file)\n",
    "                if upload_to_s3(local_file_path, bucket_name, s3_file_path):\n",
    "                    print(f\"Successfully uploaded and verified {local_file_path} to s3://{bucket_name}/{s3_file_path}\")\n",
    "                else:\n",
    "                    all_files_uploaded = False\n",
    "                    print(f\"Failed to verify {local_file_path} to s3://{bucket_name}/{s3_file_path}\")\n",
    "    \n",
    "    if all_files_uploaded:\n",
    "        print(\"All files uploaded and verified successfully.\")\n",
    "    else:\n",
    "        print(\"Some files failed to upload or verify.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2f7e5bcd-a24a-4f8a-a484-d49b4d902d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_bucket_name = 'ser-mfcc-mspectr'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae9878c-4db8-439d-a0e7-d16eb98beb6e",
   "metadata": {},
   "source": [
    "## Split datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "475cf1ac-a8e8-4011-913b-4dc6a8aefd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch as t\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b31f3c7f-cbe7-4bf4-8711-211042585904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split dataset based on session\n",
    "def split_icp_dataset(df):\n",
    "    train_df = df[df['filename'].str.startswith(('Ses01', 'Ses03', 'Ses05'))]\n",
    "    val_df = df[df['filename'].str.startswith('Ses02')]\n",
    "    test_df = df[df['filename'].str.startswith('Ses04')]\n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "10d78c50-135e-4bc1-ac99-7dbd2f9d9b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13560, 4), (4044, 4), (4536, 4))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the dataset\n",
    "icp_train_df, icp_val_df, icp_test_df = split_icp_dataset(iemocap_df)\n",
    "icp_train_df.shape, icp_val_df.shape, icp_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d50dddbc-7102-4d25-b133-dc4b34eab541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>emotion</th>\n",
       "      <th>path</th>\n",
       "      <th>school</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mont_01_000_00</td>\n",
       "      <td>0</td>\n",
       "      <td>AIBO/wav/Mont_01_000_00.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mont_01_001_00</td>\n",
       "      <td>0</td>\n",
       "      <td>AIBO/wav/Mont_01_001_00.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mont_01_001_01</td>\n",
       "      <td>0</td>\n",
       "      <td>AIBO/wav/Mont_01_001_01.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mont_01_004_00</td>\n",
       "      <td>0</td>\n",
       "      <td>AIBO/wav/Mont_01_004_00.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mont_01_005_00</td>\n",
       "      <td>0</td>\n",
       "      <td>AIBO/wav/Mont_01_005_00.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18211</th>\n",
       "      <td>Ohm_32_317_01</td>\n",
       "      <td>0</td>\n",
       "      <td>AIBO/wav/Ohm_32_317_01.wav</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18212</th>\n",
       "      <td>Ohm_32_318_00</td>\n",
       "      <td>3</td>\n",
       "      <td>AIBO/wav/Ohm_32_318_00.wav</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18213</th>\n",
       "      <td>Ohm_32_319_00</td>\n",
       "      <td>3</td>\n",
       "      <td>AIBO/wav/Ohm_32_319_00.wav</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18214</th>\n",
       "      <td>Ohm_32_320_00</td>\n",
       "      <td>0</td>\n",
       "      <td>AIBO/wav/Ohm_32_320_00.wav</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18215</th>\n",
       "      <td>Ohm_32_321_00</td>\n",
       "      <td>2</td>\n",
       "      <td>AIBO/wav/Ohm_32_321_00.wav</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18216 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             filename  emotion                         path  school\n",
       "0      Mont_01_000_00        0  AIBO/wav/Mont_01_000_00.wav       1\n",
       "1      Mont_01_001_00        0  AIBO/wav/Mont_01_001_00.wav       1\n",
       "2      Mont_01_001_01        0  AIBO/wav/Mont_01_001_01.wav       1\n",
       "3      Mont_01_004_00        0  AIBO/wav/Mont_01_004_00.wav       1\n",
       "4      Mont_01_005_00        0  AIBO/wav/Mont_01_005_00.wav       1\n",
       "...               ...      ...                          ...     ...\n",
       "18211   Ohm_32_317_01        0   AIBO/wav/Ohm_32_317_01.wav       2\n",
       "18212   Ohm_32_318_00        3   AIBO/wav/Ohm_32_318_00.wav       2\n",
       "18213   Ohm_32_319_00        3   AIBO/wav/Ohm_32_319_00.wav       2\n",
       "18214   Ohm_32_320_00        0   AIBO/wav/Ohm_32_320_00.wav       2\n",
       "18215   Ohm_32_321_00        2   AIBO/wav/Ohm_32_321_00.wav       2\n",
       "\n",
       "[18216 rows x 4 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aibo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a630d962-28d4-491d-b36c-9d47f27b6e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "aibo_df['speaker_id'] = aibo_df['filename'].apply(lambda x: x.split('_')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "64d006a3-5308-4b4a-ae3f-118b1e65f5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_aibo_dataset(df, train_ratio=0.65, val_ratio=0.15, test_ratio=0.20):\n",
    "    unique_speakers = df['speaker_id'].unique()\n",
    "    np.random.shuffle(unique_speakers)  # Shuffle to randomize\n",
    "\n",
    "    # Calculate split indices based on unique speakers\n",
    "    n_total = len(unique_speakers)\n",
    "    n_train = int(n_total * train_ratio)\n",
    "    n_val = int(n_total * val_ratio)\n",
    "\n",
    "    # Split speakers into groups\n",
    "    train_speakers = unique_speakers[:n_train]\n",
    "    val_speakers = unique_speakers[n_train:n_train + n_val]\n",
    "    test_speakers = unique_speakers[n_train + n_val:]\n",
    "\n",
    "    # Assign rows to splits based on speaker assignment\n",
    "    df['split'] = df['speaker_id'].apply(\n",
    "        lambda x: 'train' if x in train_speakers else ('val' if x in val_speakers else 'test')\n",
    "    )\n",
    "\n",
    "    # Create separate dataframes for each split\n",
    "    train_df = df[df['split'] == 'train']\n",
    "    val_df = df[df['split'] == 'val']\n",
    "    test_df = df[df['split'] == 'test']\n",
    "\n",
    "    # Optionally, you might want to drop the 'split' column if it's no longer needed\n",
    "    train_df = train_df.drop(columns=['split'])\n",
    "    val_df = val_df.drop(columns=['split'])\n",
    "    test_df = test_df.drop(columns=['split'])\n",
    "\n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6e3cbfc9-c11d-46ea-b502-557374b1f171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10990, 5), (2089, 5), (5137, 5))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the dataset\n",
    "aibo_train_df, aibo_val_df, aibo_test_df = split_aibo_dataset(aibo_df)\n",
    "aibo_train_df.shape, aibo_val_df.shape, aibo_test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a7dee9-aefe-48d6-9920-d12a18e64f38",
   "metadata": {},
   "source": [
    "## Balance train datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f4c09276-c190-49aa-8af0-92a9617fb8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "def balanced_sample_maker(X, y, random_seed=42):\n",
    "    '''\n",
    "    Take N samples from each class, where N is the number of samples in the smallest class.\n",
    "    :param X: X_train\n",
    "    :param y: y_train\n",
    "    :param random_seed: seed for reproducibility\n",
    "    :return: resampled dataset\n",
    "    '''\n",
    "    # Convert labels to tuples for compatibility with np.unique\n",
    "    y_tuples = [tuple(val) for val in y.values]\n",
    "    uniq_levels = np.unique(y_tuples, axis=0)\n",
    "\n",
    "    # Debugging: Print unique levels\n",
    "    print(\"Unique levels found:\", uniq_levels)\n",
    "    \n",
    "    if random_seed is not None:\n",
    "        np.random.seed(random_seed)\n",
    "\n",
    "    # Find observation indices of each class level\n",
    "    groupby_levels = {}\n",
    "    # Take sample size based on the class with the smallest number of samples\n",
    "    sample_size = np.inf\n",
    "    for level in uniq_levels:\n",
    "        obs_idx = [idx for idx, val in enumerate(y_tuples) if val == tuple(level)]\n",
    "        groupby_levels[tuple(level)] = obs_idx\n",
    "        if len(obs_idx) < sample_size:\n",
    "            sample_size = len(obs_idx)\n",
    "    \n",
    "    # Debugging: Print groupby_levels and sample_size\n",
    "    #print(\"Group by levels:\", groupby_levels)\n",
    "    print(\"Sample size determined:\", sample_size)\n",
    "\n",
    "    # If no sample size is found, return empty\n",
    "    if sample_size == np.inf:\n",
    "        print(\"No valid samples found for balancing.\")\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    # Downsampling observations of each label\n",
    "    balanced_copy_idx = []\n",
    "    for gb_level, gb_idx in groupby_levels.items():\n",
    "        down_sample_idx = np.random.choice(gb_idx, size=sample_size, replace=False).tolist()\n",
    "        balanced_copy_idx += down_sample_idx\n",
    "    np.random.shuffle(balanced_copy_idx)\n",
    "\n",
    "    data_train = X.iloc[balanced_copy_idx]\n",
    "    labels_train = y.iloc[balanced_copy_idx]\n",
    "    \n",
    "    if len(data_train) == (sample_size * len(uniq_levels)):\n",
    "        print('Number of samples: ', sample_size * len(uniq_levels), 'Number of samples per class: ', \\\n",
    "              sample_size, ' #classes: ', len(list(set([tuple(x) for x in uniq_levels]))))\n",
    "    else:\n",
    "        print('Number of samples is wrong!')\n",
    "\n",
    "    # Debugging: Print the shape and content of labels_train\n",
    "    print(\"Shape of labels_train:\", labels_train.shape)\n",
    "    #print(\"Content of labels_train:\", labels_train)\n",
    "    \n",
    "    if labels_train.empty:\n",
    "        print('No labels found after balancing!')\n",
    "        return data_train, labels_train\n",
    "\n",
    "    labels, values = zip(*Counter(map(tuple, labels_train.values)).items())\n",
    "    check = all(x == values[0] for x in values)\n",
    "    if check:\n",
    "        print('Good, all classes have the same number of examples')\n",
    "    else:\n",
    "        print('Repeat again your sampling, your classes are not balanced')\n",
    "    \n",
    "    return data_train, labels_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "88bb856b-6a43-4373-ab6e-40371061c09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the process_and_balance_dataset function\n",
    "def process_and_balance_dataset(df, feature_cols, label_cols, groupby_cols):\n",
    "    # Extract the features (X) and labels (y) for balancing\n",
    "    X = df[feature_cols]\n",
    "    y = df[label_cols]\n",
    "\n",
    "    # Debugging: Print the y dataframe\n",
    "    print(\"y dataframe:\")\n",
    "    print(y)\n",
    "    \n",
    "    # Balance the dataset\n",
    "    balanced_X, balanced_y = balanced_sample_maker(X, y, random_seed=42)\n",
    "\n",
    "    # Combine balanced features and labels\n",
    "    balanced_df = pd.concat([balanced_X, balanced_y], axis=1)\n",
    "\n",
    "    # Check the balanced distribution\n",
    "    #print(\"\\nBalanced distribution:\")\n",
    "    #print(balanced_df.groupby(groupby_cols).size())\n",
    "    \n",
    "    return balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9c7ab6c0-47fe-437e-ac02-f135859ffeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y dataframe:\n",
      "       emotion  gender\n",
      "0            0       1\n",
      "1            0       1\n",
      "2            0       1\n",
      "3            0       1\n",
      "4            3       1\n",
      "...        ...     ...\n",
      "22135        4       0\n",
      "22136        4       0\n",
      "22137        4       0\n",
      "22138        4       0\n",
      "22139        4       0\n",
      "\n",
      "[13560 rows x 2 columns]\n",
      "Unique levels found: [[0 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [2 0]\n",
      " [2 1]\n",
      " [3 0]\n",
      " [3 1]\n",
      " [4 0]\n",
      " [4 1]]\n",
      "Sample size determined: 789\n",
      "Number of samples:  7890 Number of samples per class:  789  #classes:  10\n",
      "Shape of labels_train: (7890, 2)\n",
      "Good, all classes have the same number of examples\n"
     ]
    }
   ],
   "source": [
    "icp_bal_train_df = process_and_balance_dataset(\n",
    "    icp_train_df, \n",
    "    feature_cols=[col for col in icp_train_df.columns if col not in ['gender', 'emotion']], \n",
    "    label_cols=['emotion', 'gender'], \n",
    "    groupby_cols=['gender', 'emotion']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b262d98f-513e-4127-b292-7979b13763b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y dataframe:\n",
      "       emotion\n",
      "0            0\n",
      "1            0\n",
      "2            0\n",
      "3            0\n",
      "4            0\n",
      "...        ...\n",
      "18211        0\n",
      "18212        3\n",
      "18213        3\n",
      "18214        0\n",
      "18215        2\n",
      "\n",
      "[10990 rows x 1 columns]\n",
      "Unique levels found: [[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]]\n",
      "Sample size determined: 362\n",
      "Number of samples:  1810 Number of samples per class:  362  #classes:  5\n",
      "Shape of labels_train: (1810, 1)\n",
      "Good, all classes have the same number of examples\n"
     ]
    }
   ],
   "source": [
    "aibo_bal_train_df = process_and_balance_dataset(\n",
    "    aibo_train_df, \n",
    "    feature_cols=[col for col in aibo_train_df.columns if col not in ['emotion']], \n",
    "    #label_cols=['school', 'emotion'], \n",
    "    label_cols=['emotion'], \n",
    "    groupby_cols=['school', 'emotion']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2272c138-65b7-4885-88c2-584840bd5907",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from file index 7890\n",
      "Problems encountered: []\n"
     ]
    }
   ],
   "source": [
    "icp_mfcc_bal_train_df, icp_mspc_bal_train_df = process_audio_features(icp_bal_train_df, \n",
    "                                                                      dataset='IEMOCAP',\n",
    "                                                                      checkpoint_file=os.path.join(LOCAL_DIR,'icp_bal_train_df_features.pkl'), \n",
    "                                                                      batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e269c228-a617-48fc-882e-6164dfa2cd52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from file index 4536\n",
      "Problems encountered: []\n"
     ]
    }
   ],
   "source": [
    "icp_mfcc_test_df, icp_mspc_test_df = process_audio_features(icp_test_df, \n",
    "                                                            dataset='IEMOCAP',\n",
    "                                                            checkpoint_file=os.path.join(LOCAL_DIR, 'icp_test_df_features.pkl'), \n",
    "                                                            batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8acf0ccc-24ce-42ed-a5b6-c82179d15f9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from file index 4044\n",
      "Problems encountered: []\n"
     ]
    }
   ],
   "source": [
    "icp_mfcc_val_df, icp_mspc_val_df = process_audio_features(icp_val_df, \n",
    "                                                          dataset='IEMOCAP',\n",
    "                                                          checkpoint_file=os.path.join(LOCAL_DIR, 'icp_val_df_features.pkl'), \n",
    "                                                          batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1cc31f7a-1f9d-4404-a345-4615c8f60bb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from file index 3720\n",
      "Problems encountered: []\n"
     ]
    }
   ],
   "source": [
    "aibo_mfcc_bal_train_df, aibo_mspc_bal_train_df = process_audio_features(aibo_bal_train_df, \n",
    "                                                                        dataset='AIBO',\n",
    "                                                                        checkpoint_file=os.path.join(LOCAL_DIR, 'aibo_bal_train_df_features.pkl'), \n",
    "                                                                        batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e11d648b-fa02-484b-a470-7d974dcc1436",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from file index 4974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1760\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5137/5137 files. Estimated time left: 0.00 minutes.\n",
      "Checkpoint saved at file index 5136\n",
      "Problems encountered: []\n"
     ]
    }
   ],
   "source": [
    "aibo_mfcc_test_df, aibo_mspc_test_df = process_audio_features(aibo_test_df, \n",
    "                                                              dataset='AIBO',\n",
    "                                                              checkpoint_file=os.path.join(LOCAL_DIR, 'aibo_test_df_features.pkl'), \n",
    "                                                              batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f3650a51-8117-473e-aebf-260f3f33c9e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from file index 3152\n",
      "Problems encountered: []\n"
     ]
    }
   ],
   "source": [
    "aibo_mfcc_val_df, aibo_mspc_val_df = process_audio_features(aibo_val_df, \n",
    "                                                            dataset='AIBO',\n",
    "                                                            checkpoint_file=os.path.join(LOCAL_DIR, 'aibo_val_df_features.pkl'), \n",
    "                                                            batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4f14d91e-b340-408d-826b-60662ff052b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_save_dir = os.path.join(LOCAL_DIR, \"mfcc_msp\")\n",
    "os.makedirs(mfcc_save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3548ab34-c651-482c-a37f-78ff0c58585c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved icp_mfcc_train to ./data/mfcc_msp/icp_mfcc_train.pkl\n",
      "Saved icp_mspc_train to ./data/mfcc_msp/icp_mspc_train.pkl\n",
      "Saved icp_mfcc_test to ./data/mfcc_msp/icp_mfcc_test.pkl\n",
      "Saved icp_mspc_test to ./data/mfcc_msp/icp_mspc_test.pkl\n",
      "Saved icp_mfcc_val to ./data/mfcc_msp/icp_mfcc_val.pkl\n",
      "Saved icp_mspc_val to ./data/mfcc_msp/icp_mspc_val.pkl\n"
     ]
    }
   ],
   "source": [
    "dataframes = {\n",
    "    \"icp_mfcc_train\": icp_mfcc_bal_train_df,\n",
    "    \"icp_mspc_train\": icp_mspc_bal_train_df,\n",
    "    \"icp_mfcc_test\": icp_mfcc_test_df,\n",
    "    \"icp_mspc_test\": icp_mspc_test_df,\n",
    "    \"icp_mfcc_val\": icp_mfcc_val_df,\n",
    "    \"icp_mspc_val\": icp_mspc_val_df\n",
    "}\n",
    "\n",
    "# Save each dataframe\n",
    "for name, df in dataframes.items():\n",
    "    file_path = os.path.join(mfcc_save_dir, f\"{name}.pkl\")\n",
    "    df.to_pickle(file_path)\n",
    "    print(f\"Saved {name} to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96896d9e-5cdd-495e-8af4-c496136640b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists: s3://ser-mfcc-mspectr/IEMOCAP/icp_mfcc_train.pkl\n",
      "Successfully uploaded and verified ./data/mfcc_msp/icp_mfcc_train.pkl to s3://ser-mfcc-mspectr/IEMOCAP/icp_mfcc_train.pkl\n",
      "File already exists: s3://ser-mfcc-mspectr/IEMOCAP/icp_mspc_train.pkl\n",
      "Successfully uploaded and verified ./data/mfcc_msp/icp_mspc_train.pkl to s3://ser-mfcc-mspectr/IEMOCAP/icp_mspc_train.pkl\n",
      "File already exists: s3://ser-mfcc-mspectr/IEMOCAP/icp_mfcc_test.pkl\n",
      "Successfully uploaded and verified ./data/mfcc_msp/icp_mfcc_test.pkl to s3://ser-mfcc-mspectr/IEMOCAP/icp_mfcc_test.pkl\n",
      "File already exists: s3://ser-mfcc-mspectr/IEMOCAP/icp_mspc_test.pkl\n",
      "Successfully uploaded and verified ./data/mfcc_msp/icp_mspc_test.pkl to s3://ser-mfcc-mspectr/IEMOCAP/icp_mspc_test.pkl\n",
      "File already exists: s3://ser-mfcc-mspectr/IEMOCAP/icp_mfcc_val.pkl\n",
      "Successfully uploaded and verified ./data/mfcc_msp/icp_mfcc_val.pkl to s3://ser-mfcc-mspectr/IEMOCAP/icp_mfcc_val.pkl\n",
      "File already exists: s3://ser-mfcc-mspectr/IEMOCAP/icp_mspc_val.pkl\n",
      "Successfully uploaded and verified ./data/mfcc_msp/icp_mspc_val.pkl to s3://ser-mfcc-mspectr/IEMOCAP/icp_mspc_val.pkl\n",
      "File already exists: s3://ser-mfcc-mspectr/IEMOCAP/aibo_mfcc_test.pkl\n",
      "Successfully uploaded and verified ./data/mfcc_msp/aibo_mfcc_test.pkl to s3://ser-mfcc-mspectr/IEMOCAP/aibo_mfcc_test.pkl\n",
      "File already exists: s3://ser-mfcc-mspectr/IEMOCAP/aibo_mspc_test.pkl\n",
      "Successfully uploaded and verified ./data/mfcc_msp/aibo_mspc_test.pkl to s3://ser-mfcc-mspectr/IEMOCAP/aibo_mspc_test.pkl\n",
      "File already exists: s3://ser-mfcc-mspectr/IEMOCAP/aibo_mfcc_val.pkl\n",
      "Successfully uploaded and verified ./data/mfcc_msp/aibo_mfcc_val.pkl to s3://ser-mfcc-mspectr/IEMOCAP/aibo_mfcc_val.pkl\n",
      "File already exists: s3://ser-mfcc-mspectr/IEMOCAP/aibo_mspc_val.pkl\n",
      "Successfully uploaded and verified ./data/mfcc_msp/aibo_mspc_val.pkl to s3://ser-mfcc-mspectr/IEMOCAP/aibo_mspc_val.pkl\n",
      "File already exists: s3://ser-mfcc-mspectr/IEMOCAP/aibo_mfcc_train.pkl\n",
      "Successfully uploaded and verified ./data/mfcc_msp/aibo_mfcc_train.pkl to s3://ser-mfcc-mspectr/IEMOCAP/aibo_mfcc_train.pkl\n",
      "File already exists: s3://ser-mfcc-mspectr/IEMOCAP/aibo_mspc_train.pkl\n",
      "Successfully uploaded and verified ./data/mfcc_msp/aibo_mspc_train.pkl to s3://ser-mfcc-mspectr/IEMOCAP/aibo_mspc_train.pkl\n",
      "All files uploaded and verified successfully.\n"
     ]
    }
   ],
   "source": [
    "upload_features_to_s3(LOCAL_DIR, mfcc_bucket_name, dataset = 'IEMOCAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d675f42-6705-4c7d-a252-a7acfedc8328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved aibo_mfcc_train to ./data/mfcc_msp/aibo_mfcc_train.pkl\n",
      "Saved aibo_mspc_train to ./data/mfcc_msp/aibo_mspc_train.pkl\n",
      "Saved aibo_mfcc_test to ./data/mfcc_msp/aibo_mfcc_test.pkl\n",
      "Saved aibo_mspc_test to ./data/mfcc_msp/aibo_mspc_test.pkl\n",
      "Saved aibo_mfcc_val to ./data/mfcc_msp/aibo_mfcc_val.pkl\n",
      "Saved aibo_mspc_val to ./data/mfcc_msp/aibo_mspc_val.pkl\n"
     ]
    }
   ],
   "source": [
    "dataframes = {\n",
    "    \"aibo_mfcc_train\": aibo_mfcc_bal_train_df,\n",
    "    \"aibo_mspc_train\": aibo_mspc_bal_train_df,\n",
    "    \"aibo_mfcc_test\": aibo_mfcc_test_df,\n",
    "    \"aibo_mspc_test\": aibo_mspc_test_df,\n",
    "    \"aibo_mfcc_val\": aibo_mfcc_val_df,\n",
    "    \"aibo_mspc_val\": aibo_mspc_val_df\n",
    "}\n",
    "\n",
    "# Save each dataframe\n",
    "for name, df in dataframes.items():\n",
    "    file_path = os.path.join(mfcc_save_dir, f\"{name}.pkl\")\n",
    "    df.to_pickle(file_path)\n",
    "    print(f\"Saved {name} to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a341e6d-cd66-4672-8bc6-d6c55723485b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists: s3://ser-mfcc-mspectr/AIBO/icp_mfcc_train.pkl\n",
      "Successfully uploaded and verified ./data/mfcc_msp/icp_mfcc_train.pkl to s3://ser-mfcc-mspectr/AIBO/icp_mfcc_train.pkl\n",
      "File already exists: s3://ser-mfcc-mspectr/AIBO/icp_mspc_train.pkl\n",
      "Successfully uploaded and verified ./data/mfcc_msp/icp_mspc_train.pkl to s3://ser-mfcc-mspectr/AIBO/icp_mspc_train.pkl\n",
      "File already exists: s3://ser-mfcc-mspectr/AIBO/icp_mfcc_test.pkl\n",
      "Successfully uploaded and verified ./data/mfcc_msp/icp_mfcc_test.pkl to s3://ser-mfcc-mspectr/AIBO/icp_mfcc_test.pkl\n",
      "File already exists: s3://ser-mfcc-mspectr/AIBO/icp_mspc_test.pkl\n",
      "Successfully uploaded and verified ./data/mfcc_msp/icp_mspc_test.pkl to s3://ser-mfcc-mspectr/AIBO/icp_mspc_test.pkl\n",
      "File already exists: s3://ser-mfcc-mspectr/AIBO/icp_mfcc_val.pkl\n",
      "Successfully uploaded and verified ./data/mfcc_msp/icp_mfcc_val.pkl to s3://ser-mfcc-mspectr/AIBO/icp_mfcc_val.pkl\n",
      "File already exists: s3://ser-mfcc-mspectr/AIBO/icp_mspc_val.pkl\n",
      "Successfully uploaded and verified ./data/mfcc_msp/icp_mspc_val.pkl to s3://ser-mfcc-mspectr/AIBO/icp_mspc_val.pkl\n",
      "File already exists: s3://ser-mfcc-mspectr/AIBO/aibo_mfcc_test.pkl\n",
      "Successfully uploaded and verified ./data/mfcc_msp/aibo_mfcc_test.pkl to s3://ser-mfcc-mspectr/AIBO/aibo_mfcc_test.pkl\n",
      "File already exists: s3://ser-mfcc-mspectr/AIBO/aibo_mspc_test.pkl\n",
      "Successfully uploaded and verified ./data/mfcc_msp/aibo_mspc_test.pkl to s3://ser-mfcc-mspectr/AIBO/aibo_mspc_test.pkl\n",
      "File already exists: s3://ser-mfcc-mspectr/AIBO/aibo_mfcc_val.pkl\n",
      "Successfully uploaded and verified ./data/mfcc_msp/aibo_mfcc_val.pkl to s3://ser-mfcc-mspectr/AIBO/aibo_mfcc_val.pkl\n",
      "File already exists: s3://ser-mfcc-mspectr/AIBO/aibo_mspc_val.pkl\n",
      "Successfully uploaded and verified ./data/mfcc_msp/aibo_mspc_val.pkl to s3://ser-mfcc-mspectr/AIBO/aibo_mspc_val.pkl\n",
      "File already exists: s3://ser-mfcc-mspectr/AIBO/aibo_mfcc_train.pkl\n",
      "Successfully uploaded and verified ./data/mfcc_msp/aibo_mfcc_train.pkl to s3://ser-mfcc-mspectr/AIBO/aibo_mfcc_train.pkl\n",
      "File already exists: s3://ser-mfcc-mspectr/AIBO/aibo_mspc_train.pkl\n",
      "Successfully uploaded and verified ./data/mfcc_msp/aibo_mspc_train.pkl to s3://ser-mfcc-mspectr/AIBO/aibo_mspc_train.pkl\n",
      "All files uploaded and verified successfully.\n"
     ]
    }
   ],
   "source": [
    "upload_features_to_s3(LOCAL_DIR, mfcc_bucket_name, dataset = 'AIBO')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b88d2b-3cdf-48c7-acee-6dac69e036ec",
   "metadata": {},
   "source": [
    "## Define Trainer and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b7273bca-6ad7-4c35-89c6-5fa4d3c574a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "import math\n",
    "from time import gmtime, strftime, time\n",
    "import torch as t\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, \n",
    "                 n_classes=5, \n",
    "                 kernel1=(3,1), \n",
    "                 kernel2=(2,1), \n",
    "                 dur=50, \n",
    "                 numcep=40, \n",
    "                 input_type=\"mfcc\", \n",
    "                 dataset=None):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # Input shape = (batch_size, 1, numceps=40, mfcc_dur=50)\n",
    "        # Input (batch_size, num_channels, height, width)\n",
    "        # Output size after convolution filter = ((w-kernel_size/filter_size+2P)/s) +1\n",
    "        self.dur = dur\n",
    "        self.numcep = numcep\n",
    "        self.n_classes = n_classes\n",
    "        self.input_type = input_type\n",
    "        self.kernel1 = kernel1\n",
    "        self.kernel2 = kernel2\n",
    "\n",
    "        #kernel_size=(3,1) not to influence time dimension\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=kernel1) # stride=1\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=64)      # num_features = num_filters\n",
    "        self.relu1 = nn.ELU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=kernel2)     # (2,1) or 2\n",
    "        self.drop1 = nn.Dropout(0.5)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=kernel1)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=64)\n",
    "        self.relu2 = nn.ELU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=kernel2)\n",
    "        self.drop2 = nn.Dropout(0.25)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=kernel1)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=64)\n",
    "        self.relu3 = nn.ELU()\n",
    "        #self.pool3 = nn.MaxPool2d(kernel_size=kernel_size2)\n",
    "        self.drop3 = nn.Dropout(0.25)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=self.n_classes, kernel_size=kernel1)\n",
    "        self.bn4 = nn.BatchNorm2d(num_features=self.n_classes)\n",
    "        self.relu4 = nn.ELU()\n",
    "        #self.pool4 = nn.MaxPool2d(kernel_size=kernel_size2)\n",
    "        self.drop4 = nn.Dropout(0.25)\n",
    "\n",
    "        out_lin_dim = self._calc_lin_dim(self.numcep, self.dur, self.kernel1, self.kernel2)\n",
    "        self.fc = nn.Linear(in_features=out_lin_dim, out_features=256)\n",
    "        self.relu4 = nn.GELU()\n",
    "        self.fc1 = nn.Linear(in_features=256, out_features=self.n_classes)\n",
    "\n",
    "    def _calc_lin_dim(self, numcep, dur, kernel1, kernel2):\n",
    "        def conv2d_size_out(size, kernel_size, stride=1, padding=0):\n",
    "            return (size - kernel_size + 1) // stride\n",
    "    \n",
    "        def pool2d_size_out(size, kernel_size, stride=None):\n",
    "            if stride is None:\n",
    "                stride = kernel_size\n",
    "            return size // stride\n",
    "    \n",
    "        # Calculate for both dimensions\n",
    "        out_h = numcep\n",
    "        out_w = dur\n",
    "    \n",
    "        # Conv1 + Pool1\n",
    "        out_h = conv2d_size_out(out_h, kernel1[0])\n",
    "        out_w = conv2d_size_out(out_w, kernel1[1])\n",
    "        out_h = pool2d_size_out(out_h, kernel2[0])\n",
    "        out_w = pool2d_size_out(out_w, kernel2[1])\n",
    "    \n",
    "        # Conv2 + Pool2\n",
    "        out_h = conv2d_size_out(out_h, kernel1[0])\n",
    "        out_w = conv2d_size_out(out_w, kernel1[1])\n",
    "        out_h = pool2d_size_out(out_h, kernel2[0])\n",
    "        out_w = pool2d_size_out(out_w, kernel2[1])\n",
    "    \n",
    "        # Conv3\n",
    "        out_h = conv2d_size_out(out_h, kernel1[0])\n",
    "        out_w = conv2d_size_out(out_w, kernel1[1])\n",
    "    \n",
    "        # Conv4\n",
    "        out_h = conv2d_size_out(out_h, kernel1[0])\n",
    "        out_w = conv2d_size_out(out_w, kernel1[1])\n",
    "    \n",
    "        out_lin = out_h * out_w * self.n_classes\n",
    "        #print(f\"Calculated linear dimension: {out_lin}\")\n",
    "        return out_lin\n",
    "\n",
    "    # Feed forward function\n",
    "    def forward(self, input):\n",
    "        #print(f\"Input shape: {input.shape}\")\n",
    "        output = self.conv1(input)\n",
    "        #print(f\"After conv1: {output.shape}\")\n",
    "        output = self.bn1(output)\n",
    "        output = self.relu1(output)\n",
    "        output = self.pool1(output)\n",
    "        output = self.drop1(output)\n",
    "        #print(f\"After pool1: {output.shape}\")\n",
    "    \n",
    "        output = self.conv2(output)\n",
    "        #print(f\"After conv2: {output.shape}\")\n",
    "        output = self.bn2(output)\n",
    "        output = self.relu2(output)\n",
    "        output = self.pool2(output)\n",
    "        output = self.drop2(output)\n",
    "        #print(f\"After pool2: {output.shape}\")\n",
    "    \n",
    "        output = self.conv3(output)\n",
    "        #print(f\"After conv3: {output.shape}\")\n",
    "        output = self.bn3(output)\n",
    "        output = self.relu3(output)\n",
    "        output = self.drop3(output)\n",
    "    \n",
    "        output = self.conv4(output)\n",
    "        #print(f\"After conv4: {output.shape}\")\n",
    "        output = self.bn4(output)\n",
    "        output = self.relu4(output)\n",
    "        output = self.drop4(output)\n",
    "    \n",
    "        output = output.view(output.size(0), -1)\n",
    "        #print(f\"After flattening: {output.shape}\")\n",
    "    \n",
    "        output = self.fc(output)\n",
    "        #print(f\"After fc: {output.shape}\")\n",
    "        output = self.relu4(output)\n",
    "        output = self.fc1(output)\n",
    "        #print(f\"Final output: {output.shape}\")\n",
    "        return output\n",
    "\n",
    "\n",
    "class Conv_GRU(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 input_shape, \n",
    "                 hidden_size, \n",
    "                 kernel1, \n",
    "                 kernel2, \n",
    "                 bidirectional=True, \n",
    "                 nlayers_rnn=2, \n",
    "                 n_classes=5, \n",
    "                 dataset='None'):\n",
    "        super(Conv_GRU, self).__init__()\n",
    "\n",
    "        self.input_shape = input_shape  # [batch size, channels, sequence length, # MFCCs]\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bidirectional = bidirectional\n",
    "        self.nlayers_Bigru = nlayers_rnn\n",
    "        self.n_classes = n_classes\n",
    "        self.n_ch = 4\n",
    "        self.kernel1 = kernel1\n",
    "        self.kernel2 = kernel2\n",
    "\n",
    "        #CNN\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=self.kernel1)  # stride=1\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=64)  # num_features = num_filters\n",
    "        self.relu1 = nn.ELU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=self.kernel2)\n",
    "        self.drop1 = nn.Dropout(0.5)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=self.kernel1)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=64)\n",
    "        self.relu2 = nn.ELU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=self.kernel2)     # stride=(4,4)\n",
    "        self.drop2 = nn.Dropout(0.25)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=self.kernel1)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=64)\n",
    "        self.relu3 = nn.ELU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=self.kernel2)\n",
    "        self.drop3 = nn.Dropout(0.25)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=self.n_classes, kernel_size=self.kernel1)\n",
    "        self.bn4 = nn.BatchNorm2d(num_features=self.n_classes)\n",
    "        self.relu4 = nn.ELU()\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=self.kernel2)\n",
    "        self.drop4 = nn.Dropout(0.25)\n",
    "\n",
    "        outConvShape = self.get_conv_output(self.input_shape)\n",
    "        # Number of features\n",
    "        #input_size = self.n_ch * outConvShape   # 4*140\n",
    "\n",
    "        # GRU\n",
    "        if dataset=='aibo':\n",
    "            #if input ==\"mspectr\":\n",
    "             #   self.GRU = t.nn.GRU(130, self.hidden_size,\n",
    "              #                      bidirectional=self.bidirectional,\n",
    "               #                     num_layers=self.nlayers_Bigru,\n",
    "                #                    batch_first=True)\n",
    "            self.GRU = t.nn.GRU(20, self.hidden_size,\n",
    "                                    bidirectional=self.bidirectional,\n",
    "                                    num_layers=self.nlayers_Bigru,\n",
    "                                    batch_first=True)\n",
    "        else:\n",
    "            self.GRU = t.nn.GRU(outConvShape[2], self.hidden_size,\n",
    "                                bidirectional=self.bidirectional,\n",
    "                                num_layers=self.nlayers_Bigru,\n",
    "                                batch_first=True)\n",
    "\n",
    "        self.BatchNorm_biGru = t.nn.BatchNorm1d(outConvShape[1])  # Output\n",
    "\n",
    "        # In case of bidirectional recurrent network\n",
    "        idx_bi = 1\n",
    "        if self.bidirectional:\n",
    "            idx_bi = 2\n",
    "\n",
    "        # Linear transformation - Affine mapping\n",
    "        # As we are concatenating everything for the linear layer->\n",
    "        #output_biGru = int((self.hidden_size * idx_bi)) * self.input_shape[3]\n",
    "        output_biGru = int(self.hidden_size * idx_bi * outConvShape[1])     # hid_size * bidir_index * seq_len\n",
    "        self.drop_gru = t.nn.Dropout(0.25)\n",
    "        self.fc_gru1 = t.nn.Linear(output_biGru, 256)\n",
    "        self.fc_gru2 = t.nn.Linear(in_features=256, out_features=self.n_classes)\n",
    "\n",
    "    # generate input sample and forward to get shape\n",
    "    def get_conv_output(self, shape):\n",
    "        # generates a variable equal to the input to compute automatically the dimensions for the output of the conv and the input of the gru\n",
    "        #input = Variable(t.rand(*shape))       # * to switch from 0.abcd to scientific notation\n",
    "        input = t.rand(shape)\n",
    "        output = self._forward_Conv(input)\n",
    "        output = output.permute(0, 3, 1, 2)\n",
    "        out = output.contiguous().view(output.shape[0], output.shape[1], -1)\n",
    "        return out.shape\n",
    "\n",
    "    def _forward_Conv(self, input):\n",
    "        \"\"\"\n",
    "        Convolutional layer features\n",
    "        ReLU, and max pooling\n",
    "        \"\"\"\n",
    "        output = self.conv1(input)\n",
    "        output = self.bn1(output)\n",
    "        output = self.relu1(output)\n",
    "        output = self.pool1(output)\n",
    "        output = self.drop1(output)\n",
    "\n",
    "        output = self.conv2(output)\n",
    "        output = self.bn2(output)\n",
    "        output = self.relu2(output)\n",
    "        output = self.pool2(output)\n",
    "        output = self.drop2(output)\n",
    "\n",
    "        output = self.conv3(output)\n",
    "        output = self.bn3(output)\n",
    "        output = self.relu3(output)\n",
    "        output = self.drop3(output)\n",
    "\n",
    "        output = self.conv4(output)\n",
    "        output = self.bn4(output)\n",
    "        output = self.relu4(output)\n",
    "        output = self.drop4(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        \"\"\"\n",
    "        GRU layer\n",
    "        batchnorm and dropout\n",
    "        \"\"\"\n",
    "\n",
    "        out = self._forward_Conv(input_tensor)\n",
    "        out = out.permute(0, 3, 1, 2)  # Permute dimensions to keep one-to-one context\n",
    "        # from [batch size, channels, sequence length, # MFCCs] to [batch size, sequence length, channels, # MFCCs]\n",
    "        out = out.contiguous().view(out.shape[0], out.shape[1], -1)\n",
    "        # Concatenate sequence length and resulting # MFCCs -> [batch size, sequence length, channels*# MFCCs]\n",
    "\n",
    "        # GRU\n",
    "        #print(out.shape)\n",
    "        out, _ = self.GRU(out)\n",
    "        out = self.BatchNorm_biGru(out)\n",
    "        out = self.fc_gru1(out.view(out.size(0), -1))\n",
    "        out = self.drop_gru(F.gelu(out))\n",
    "        out = self.fc_gru2(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "639ca715-2b51-4095-9c72-21468aa413d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if t.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    else:\n",
    "        return \"cpu\"\n",
    "\n",
    "def get_datetime():\n",
    "    # storing per day to have different runs from different days\n",
    "    return strftime(\"%Y-%m-%d\", gmtime())\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    # https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, epoch=-1, verbose=False, delta=0, trace_func=print):\n",
    "    #def __init__(self, patience=7, epoch=0, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.epoch = epoch\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.trace_func = trace_func\n",
    "\n",
    "    def __call__(self, val_loss, model, model_name, dataset):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, model_name, dataset)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                print(\"EarlyStopping counter is higher than patience\")\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, model_name, dataset)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model, model_name, dataset):\n",
    "        \"\"\"\n",
    "        Saves model when validation loss decreases\n",
    "        \"\"\"\n",
    "        if not os.path.isdir('./checkpoints/'):\n",
    "            os.makedirs('./checkpoints/')\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        #a.save(model.state_dict(), self.path)\n",
    "        path = 'checkpoints/' + model_name + dataset + '_checkpoint_{}.ckp'.format(get_datetime())\n",
    "        t.save({'state_dict': model.state_dict()}, path)\n",
    "        self.val_loss_min = val_loss\n",
    "        #t.save({'state_dict': self._model.state_dict()}, 'checkpoints/' + model_name + 'checkpoint.ckp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d9ec8913-02ca-46d4-8dc4-b29385d446a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, f1_score, accuracy_score\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "\n",
    "    def __init__(self,\n",
    "                 model,  # Model to be trained.\n",
    "                 model_name,\n",
    "                 dataset,\n",
    "                 crit,  # Loss function\n",
    "                 optim=None,  # Optimizer\n",
    "                 train_dl=None,  # Training data set\n",
    "                 val_test_dl=None,  # Validation data set\n",
    "                 test_dl=None,  # Test data set\n",
    "                 cuda=False,  # Whether to use the GPU\n",
    "                 early_stopping_patience=10,  # The patience for early stopping\n",
    "                 unsqueeze_needed=True,\n",
    "                 CLASS_TO_ID=None):\n",
    "                 #ID_TO_CLASS=None,\n",
    "                 #CLASSNAMES=None):\n",
    "\n",
    "        self._model = model\n",
    "        self.model_name = model_name\n",
    "        self.dataset = dataset\n",
    "        self._crit = crit\n",
    "        self._optim = optim\n",
    "        self._train_dl = train_dl\n",
    "        self._val_test_dl = val_test_dl\n",
    "        self._test_dl = test_dl\n",
    "        self._cuda = cuda\n",
    "        self._early_stopping_patience = early_stopping_patience\n",
    "        self._unsqueeze_needed = unsqueeze_needed\n",
    "        self.CLASS_TO_ID = CLASS_TO_ID\n",
    "\n",
    "    \n",
    "    def restore_checkpoint(self):\n",
    "        path = 'checkpoints/' + self.model_name + '_checkpoint_{}.ckp'.format(get_datetime())\n",
    "        if os.path.exists(path):\n",
    "            ckp = t.load(path, 'cuda' if self._cuda else None)\n",
    "            self._model.load_state_dict(ckp['state_dict'])\n",
    "\n",
    "    def save_onnx(self, fn):\n",
    "        m = self._model.cpu()\n",
    "        m.eval()\n",
    "        x = t.randn(1, 3, 300, 300, requires_grad=True)\n",
    "        y = self._model(x)\n",
    "        t.onnx.export(m,  # model being run\n",
    "                      x,  # model input (or a tuple for multiple inputs)\n",
    "                      fn,  # where to save the model (can be a file or file-like object)\n",
    "                      export_params=True,  # store the trained parameter weights inside the model file\n",
    "                      opset_version=10,  # the ONNX version to export the model to\n",
    "                      do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                      input_names=['input'],  # the model's input names\n",
    "                      output_names=['output'],  # the model's output names\n",
    "                      dynamic_axes={'input': {0: 'batch_size'},  # variable lenght axes\n",
    "                                    'output': {0: 'batch_size'}})\n",
    "\n",
    "    def train_step(self, x, y):\n",
    "        # perform following steps:\n",
    "        # -reset the gradients / clear the gradients of all optimized variables\n",
    "        self._optim.zero_grad()\n",
    "        # -propagate through the network / forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = self._model.forward(x)\n",
    "        # -calculate the loss\n",
    "        # y=y.to(t.int64)\n",
    "\n",
    "        loss = self._crit(output, y)\n",
    "        # -compute gradient by backprop / backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # -update weights / perform a single optimization step (parameter update)\n",
    "        self._optim.step()\n",
    "        # -return the loss\n",
    "        return loss, output\n",
    "\n",
    "    def val_test_step(self, x, y):\n",
    "        # predict\n",
    "        # propagate through the network and calculate the loss and predictions\n",
    "        pred = self._model.forward(x)\n",
    "        # calculate the loss\n",
    "        # y=y.to(t.int64)\n",
    "\n",
    "        loss = self._crit(pred, y)\n",
    "        # return the loss and the predictions\n",
    "        return loss, pred\n",
    "\n",
    "    def train_epoch(self):\n",
    "        # set training mode / prepare model for training\n",
    "        self._model.train()\n",
    "        # iterate through the training set\n",
    "        # clear lists to track next epoch\n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "        for x, y in self._train_dl:\n",
    "            # transfer the batch to \"cuda()\" -> the gpu if a gpu is given\n",
    "            if self._cuda:\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "            if self._unsqueeze_needed:\n",
    "                x = x.unsqueeze(1)\n",
    "            # perform a training step\n",
    "            # print(y.dtype)\n",
    "            loss, pred = self.train_step(x, y)\n",
    "            total_loss += loss.item()\n",
    "            # total_acc += accuracy_score(y.cpu().detach().numpy(), np.hstack(pred))\n",
    "            # total_acc += accuracy_score(y.cpu(), pred.cpu() > 0.5)\n",
    "        # calculate the average loss for the epoch and return it\n",
    "        total_loss = total_loss / len(self._train_dl)\n",
    "        # total_acc = total_acc / len(self._train_dl)\n",
    "        # print(\"Train: loss: {}, accuracy: {}\".format(total_loss, total_acc))\n",
    "        print(\"Train: loss: {}\".format(total_loss))\n",
    "        return total_loss\n",
    "\n",
    "    def val_test(self, mode=False):\n",
    "        self._model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        total_loss = 0\n",
    "    \n",
    "        with t.no_grad():\n",
    "            dataset = self._test_dl if mode else self._val_test_dl\n",
    "            for x, y in dataset:\n",
    "                if self._cuda:\n",
    "                    x, y = x.cuda(), y.cuda()\n",
    "                x = x.unsqueeze(1)\n",
    "                \n",
    "                loss, pred = self.val_test_step(x, y)\n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                activation = t.nn.Softmax(dim=1)\n",
    "                pred = activation(pred.data)\n",
    "                pred = t.max(pred, 1)[1]\n",
    "                \n",
    "                all_preds.extend(pred.cpu().numpy())\n",
    "                all_labels.extend(y.cpu().numpy())\n",
    "    \n",
    "        all_preds = np.array(all_preds)\n",
    "        all_labels = np.array(all_labels)\n",
    "        \n",
    "        total_loss /= len(dataset)\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        \n",
    "        # Print class distribution\n",
    "        unique, counts = np.unique(all_labels, return_counts=True)\n",
    "        print(\"True label distribution:\", dict(zip(unique, counts)))\n",
    "        unique, counts = np.unique(all_preds, return_counts=True)\n",
    "        print(\"Predicted label distribution:\", dict(zip(unique, counts)))\n",
    "        \n",
    "        # Calculate recall for each class\n",
    "        #for i, recall in enumerate(recall_per_class):\n",
    "            #print(f\"Recall for class {i}: {recall}\")\n",
    "        \n",
    "        # Calculate overall metrics\n",
    "        f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "        recall = recall_score(all_labels, all_preds, average='macro')\n",
    "    \n",
    "        if mode:\n",
    "            print(f\"Test - Loss: {total_loss:.4f}, Accuracy: {accuracy*100:.2f}%, Recall: {recall*100:.2f}%, F1-Score: {f1*100:.2f}%\")\n",
    "        else:\n",
    "            print(f\"Validation - Loss: {total_loss:.4f}, Accuracy: {accuracy*100:.2f}%, Recall: {recall*100:.2f}%, F1-Score: {f1*100:.2f}%\")\n",
    "    \n",
    "        return (total_loss, all_preds) if mode else total_loss\n",
    "\n",
    "    def fit(self, n_epochs):\n",
    "        # to track the training loss as the model trains\n",
    "        # train_losses = []\n",
    "        # to track the validation loss as the model trains\n",
    "        # valid_losses = []\n",
    "        # to track the average training loss per epoch as the model trains\n",
    "        avg_train_losses = []\n",
    "        # to track the average validation loss per epoch as the model trains\n",
    "        avg_valid_losses = []\n",
    "        # store results\n",
    "        # res = open('./results/' + self.model_name + '_results.txt', 'w')\n",
    "        # res.write(50 * '=')\n",
    "        # res.write('Model \\n')\n",
    "        # res.write(str(self._model) + '\\n')\n",
    "\n",
    "        # load the last checkpoint with the best model\n",
    "        self.restore_checkpoint()\n",
    "\n",
    "        # initialize the early_stopping object\n",
    "        early_stopping = EarlyStopping(patience=self._early_stopping_patience, verbose=True)\n",
    "\n",
    "        for epoch in range(1, n_epochs + 1):\n",
    "            # train the model\n",
    "            train_loss = self.train_epoch()\n",
    "            # validate the model\n",
    "            valid_loss = self.val_test(mode=False)\n",
    "\n",
    "            # calculate average loss over an epoch\n",
    "            # train_loss = np.average(train_losses)\n",
    "            # train_loss = train_losses / len(self._train_dl)\n",
    "            # valid_loss = np.average(valid_losses)\n",
    "\n",
    "            avg_train_losses.append(train_loss)\n",
    "            avg_valid_losses.append(valid_loss)\n",
    "\n",
    "            \"\"\"\n",
    "            # print training/validation statistics\n",
    "            epoch_len = len(str(n_epochs))\n",
    "\n",
    "            print_msg = (f'[{epoch:>{epoch_len}}/{n_epochs:>{epoch_len}}] ' +\n",
    "                         f'train_loss: {train_loss:.5f} ' +\n",
    "                         f'valid_loss: {valid_loss:.5f}')\n",
    "\n",
    "            print(print_msg)\n",
    "            \"\"\"\n",
    "\n",
    "            # early_stopping needs the validation loss to check if it has decreased,\n",
    "            # if it has, it will make a checkpoint of the current model\n",
    "            early_stopping(valid_loss, self._model, self.model_name, self.dataset)\n",
    "\n",
    "            \"\"\"\n",
    "            # use the save_checkpoint function to save the model for each epoch\n",
    "            save_flag = self._early_stopping_cb.step(l_dev)\n",
    "\n",
    "            if save_flag:\n",
    "                res.write(50 * '=')\n",
    "                res.write('Epoch: ' + str(self.epoch) + ' Training Loss :' + str(l_train) + ' Development Loss :' + str(\n",
    "                    l_dev))\n",
    "                Trainer.save_checkpoint(self, self.epoch + 1, model_name)\n",
    "                self.epoch_n = self.epoch + 1\n",
    "            \"\"\"\n",
    "\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping has been reached\")\n",
    "                break\n",
    "\n",
    "            # load the last checkpoint with the best model\n",
    "            # self._model.load_state_dict(t.load('checkpoint.pt'))\n",
    "            # self.restore_checkpoint()\n",
    "\n",
    "        # return model, avg_train_losses, avg_valid_losses\n",
    "        # res.close()\n",
    "        return avg_train_losses, avg_valid_losses\n",
    "\n",
    "    def test(self):\n",
    "\n",
    "        # load the last checkpoint with the best model\n",
    "        self.restore_checkpoint()\n",
    "\n",
    "        # test the model\n",
    "        test_loss, all_preds = self.val_test(mode=True)\n",
    "\n",
    "        # output recall and f1\n",
    "        y_true = np.concatenate([y.cpu().numpy() for _, y in self._test_dl])\n",
    "        \n",
    "        accuracy = accuracy_score(y_true, all_preds)\n",
    "        f1 = f1_score(y_true, all_preds, average='macro')\n",
    "        recall = recall_score(y_true, all_preds, average='macro')\n",
    "        return test_loss, all_preds, accuracy, f1, recall\n",
    "\n",
    "    def get_dataset(self):\n",
    "        return self.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ab32fe44-3f3f-4645-8372-d747d0d75c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title=None, normalize=True, cmap=plt.cm.RdPu):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set values from 0 to 1\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title('Confusion matrix for {}'.format(title))\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, \"{:.2f}\".format(cm[i, j]),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig('baseline_results/conf_matrix_{}.svg'.format(title))\n",
    "\n",
    "\n",
    "def one_hot_encoder(true_labels, num_records, num_classes):\n",
    "    temp = np.array(true_labels[:num_records])\n",
    "    true_labels = np.zeros((num_records, num_classes))\n",
    "    true_labels[np.arange(num_records), temp] = 1\n",
    "    return true_labels\n",
    "\n",
    "def display_results(y_test, pred_probs, dataset, model, model_input):\n",
    "    pred = np.argmax(pred_probs, axis=-1)\n",
    "    #one_hot_true = one_hot_encoder(y_test, len(pred), len(ICP_CLASS_TO_ID))\n",
    "    #one_hot_true = one_hot_encoder(y_test, len(pred_probs), len(ICP_CLASS_TO_ID))\n",
    "    acc = 'Test Set Accuracy =  {0:.3f}'.format(accuracy_score(y_test, pred))\n",
    "    fscore = 'Test Set F-score =  {0:.3f}'.format(f1_score(y_test, pred, average='macro'))\n",
    "    prec = 'Test Set Precision =  {0:.3f}'.format(precision_score(y_test, pred, average='macro'))\n",
    "    rec = 'Test Set Recall =  {0:.3f}'.format(recall_score(y_test, pred, average='macro'))\n",
    "    metrics = [acc, fscore, prec, rec]\n",
    "    cr = classification_report(y_true=y_test, \n",
    "                               y_pred=pred, \n",
    "                               target_names=list(emotion_mapping.keys()))\n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "    title = f\"{model}_{dataset}_with_{model_input_}\"\n",
    "    f = open('baseline_results/report_{}.txt'.format(title), 'w')\n",
    "    f.write('RESULTS\\n\\nMetrics\\n\\n{}\\n\\nClassification Report\\n\\n{}\\n\\nConfusion Matrix\\n\\n{}\\n'.format(metrics, cr, cm))\n",
    "    f.close()\n",
    "    print(cr)\n",
    "    plot_confusion_matrix(cm=cm, \n",
    "                          classes=list(ICP_ID_TO_CLASS.values()), \n",
    "                          title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128826cc-2d93-4048-8a6f-d72cb02a3bde",
   "metadata": {},
   "source": [
    "## Run Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3f96c736-133a-4d31-abb4-a86083b74458",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('baseline_results', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "204bcf48-b332-45a7-9ce1-b3dda50b09fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'model_name': 'cnn',  # or 'gru'\n",
    "    'dataset': 'iemocap',  # or 'aibo'\n",
    "    'model_input': 'mfcc',  # or 'mspc'\n",
    "    'batch_size': 10,\n",
    "    'epochs': 10,\n",
    "    'lr': 0.0001,\n",
    "    'w_decay': 0.00001\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "617b7dab-7125-4c99-a945-c14d3239c89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define the normalization function\n",
    "def normalize(tensor, min_vals, max_vals):\n",
    "    '''\n",
    "    Normalize the tensor using min/max values.\n",
    "    min_vals/max_vals are tensors that match the feature dimensions.\n",
    "    :return: Normalized tensor\n",
    "    '''\n",
    "    tensor_norm = (tensor - min_vals) / (max_vals - min_vals)\n",
    "    return tensor_norm\n",
    "\n",
    "# Function to calculate min and max values for normalization\n",
    "def calculate_min_max(df, feature_col):\n",
    "    features = np.array(df[feature_col].tolist())\n",
    "    #print(f\"Feature shape (before min/max calculation): {features.shape}\")  # Debug statement\n",
    "    min_vals = features.min(axis=(0, 2), keepdims=True)\n",
    "    max_vals = features.max(axis=(0, 2), keepdims=True)\n",
    "    #print(f\"Min values shape: {min_vals.shape}, Max values shape: {max_vals.shape}\")  # Debug statement\n",
    "    return t.tensor(min_vals, dtype=t.float32), t.tensor(max_vals, dtype=t.float32)\n",
    "\n",
    "# Function to create a tensor dataset and DataLoader\n",
    "def create_tensor_dataset(df, feature_col='mfcc', label_col='emotion', \n",
    "                          min_vals=None, max_vals=None, shuffle=False, batch_size=32):\n",
    "    \"\"\"\n",
    "    Creates a PyTorch DataLoader from a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    X = df[feature_col].tolist()  # Convert to list if it's not already\n",
    "    y = df[label_col].values\n",
    "    \n",
    "    X_tensor = t.tensor(X, dtype=t.float32)\n",
    "    y_tensor = t.tensor(y, dtype=t.long)\n",
    "    \n",
    "    if min_vals is not None and max_vals is not None:\n",
    "        X_tensor = normalize(X_tensor, min_vals, max_vals)\n",
    "    \n",
    "    dataset = TensorDataset(X_tensor, y_tensor)\n",
    "    data_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    \n",
    "    return data_loader\n",
    "\n",
    "# Function to get data loaders based on the dataset type and model input\n",
    "def get_data_loaders(args):\n",
    "    try:\n",
    "        dataset_type = f\"{args['dataset']}_{args['model_input']}\"\n",
    "        \n",
    "        if dataset_type == 'iemocap_mfcc':\n",
    "            min_vals, max_vals = calculate_min_max(icp_mfcc_bal_train_df, 'mfcc')\n",
    "            train_loader = create_tensor_dataset(icp_mfcc_bal_train_df, 'mfcc', 'emotion', min_vals, max_vals, shuffle=True, batch_size=args['batch_size'])\n",
    "            val_loader = create_tensor_dataset(icp_mfcc_val_df, 'mfcc', 'emotion', min_vals, max_vals, shuffle=True, batch_size=args['batch_size'])\n",
    "            test_loader = create_tensor_dataset(icp_mfcc_test_df, 'mfcc', 'emotion', min_vals, max_vals, shuffle=False, batch_size=args['batch_size'])\n",
    "        elif dataset_type == 'iemocap_mspc':\n",
    "            min_vals, max_vals = calculate_min_max(icp_mspc_bal_train_df, 'mel_spectr')\n",
    "            train_loader = create_tensor_dataset(icp_mspc_bal_train_df, 'mel_spectr', 'emotion', min_vals, max_vals, shuffle=True, batch_size=args['batch_size'])\n",
    "            val_loader = create_tensor_dataset(icp_mspc_val_df, 'mel_spectr', 'emotion', min_vals, max_vals, shuffle=True, batch_size=args['batch_size'])\n",
    "            test_loader = create_tensor_dataset(icp_mspc_test_df, 'mel_spectr', 'emotion', min_vals, max_vals, shuffle=False, batch_size=args['batch_size'])\n",
    "        elif dataset_type == 'aibo_mfcc':\n",
    "            min_vals, max_vals = calculate_min_max(aibo_mfcc_bal_train_df, 'mfcc')\n",
    "            train_loader = create_tensor_dataset(aibo_mfcc_bal_train_df, 'mfcc', 'emotion', min_vals, max_vals, shuffle=True, batch_size=args['batch_size'])\n",
    "            val_loader = create_tensor_dataset(aibo_mfcc_val_df, 'mfcc', 'emotion', min_vals, max_vals, shuffle=True, batch_size=args['batch_size'])\n",
    "            test_loader = create_tensor_dataset(aibo_mfcc_test_df, 'mfcc', 'emotion', min_vals, max_vals, shuffle=False, batch_size=args['batch_size'])\n",
    "        elif dataset_type == 'aibo_mspc':\n",
    "            min_vals, max_vals = calculate_min_max(aibo_mspc_bal_train_df, 'mel_spectr')\n",
    "            train_loader = create_tensor_dataset(aibo_mspc_bal_train_df, 'mel_spectr', 'emotion', min_vals, max_vals, shuffle=True, batch_size=args['batch_size'])\n",
    "            val_loader = create_tensor_dataset(aibo_mspc_val_df, 'mel_spectr', 'emotion', min_vals, max_vals, shuffle=True, batch_size=args['batch_size'])\n",
    "            test_loader = create_tensor_dataset(aibo_mspc_test_df, 'mel_spectr', 'emotion', min_vals, max_vals, shuffle=False, batch_size=args['batch_size'])\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown dataset: {args['dataset']}\")\n",
    "        \n",
    "        return train_loader, val_loader, test_loader\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in getting data loaders for {args['dataset']}, {args['model_input']}: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Function to get class to ID mapping based on the dataset\n",
    "def get_class_to_id(dataset):\n",
    "    if dataset == 'iemocap':\n",
    "        return ICP_CLASS_TO_ID\n",
    "    elif dataset == 'aibo':\n",
    "        return AIBO_CLASS_TO_ID\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown dataset: {dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9958374b-de64-4253-91b4-270d96c66f47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1568c9-d480-4a09-9cec-0cbf5f47eb01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4caca00c-3174-471f-a3ca-c2ae68ed24f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import torch as t\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "def run_combined_experiments_aibo(base_args):\n",
    "    results = []\n",
    "    \n",
    "    model_names = ['gru', 'cnn']\n",
    "    datasets = ['aibo']\n",
    "    model_inputs = ['mfcc', 'mspc']\n",
    "\n",
    "    for model_name, dataset, model_input in product(model_names, datasets, model_inputs):\n",
    "        # Create a unique filename for this specific combination\n",
    "        csv_filename = f\"baseline_results/experiment_results_{model_name}_{dataset}_{model_input}.csv\"\n",
    "        \n",
    "        # If the CSV file already exists, skip this experiment\n",
    "        if os.path.isfile(csv_filename):\n",
    "            print(f\"Skipping experiment with: {model_name}, {dataset}, {model_input} (CSV file already exists)\")\n",
    "            continue\n",
    "\n",
    "        args = {**base_args, 'model_name': model_name, 'dataset': dataset, 'model_input': model_input}\n",
    "\n",
    "        try:\n",
    "            print(f\"Running experiment with: {args}\")\n",
    "            \n",
    "            # Initialize device\n",
    "            device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")\n",
    "            \n",
    "            # Load data\n",
    "            train_loader, val_loader, test_loader = get_data_loaders(args)\n",
    "            \n",
    "            # Initialize model based on the configuration\n",
    "            if model_name == 'cnn':\n",
    "                if model_input == 'mfcc':\n",
    "                    model = CNN(n_classes=5, dur=MFCC_DUR, numcep=NUMCEP, input_type=\"mfcc\",\n",
    "                                kernel1=(3,3), kernel2=(2,2)).to(device)\n",
    "                else:  # mspc\n",
    "                    model = CNN(n_classes=5, dur=50, numcep=SPECTR_DUR, input_type=\"mspc\",\n",
    "                                kernel1=(3,3), kernel2=(2,2)).to(device)\n",
    "            elif model_name == 'gru':\n",
    "                if model_input == 'mfcc':\n",
    "                    model = Conv_GRU(\n",
    "                        input_shape=[args['batch_size'], 1, NUMCEP, MFCC_DUR], \n",
    "                        hidden_size=32, \n",
    "                        kernel1=(3, 3), \n",
    "                        kernel2=(2, 2)).to(device)\n",
    "                else:\n",
    "                    model = Conv_GRU(\n",
    "                        input_shape=[args['batch_size'], 1, SPECTR_DUR, MFCC_DUR], \n",
    "                        hidden_size=32, \n",
    "                        kernel1=(3, 3), \n",
    "                        kernel2=(2, 2)).to(device)\n",
    "\n",
    "            # Setup optimizer and loss function\n",
    "            optimizer = Adam(model.parameters(), lr=args['lr'], weight_decay=args['w_decay'])\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            \n",
    "            # Create an instance of Trainer\n",
    "            trainer = Trainer(\n",
    "                model=model,\n",
    "                model_name=model_name,\n",
    "                dataset=dataset,\n",
    "                crit=criterion,\n",
    "                optim=optimizer,\n",
    "                train_dl=train_loader,\n",
    "                val_test_dl=val_loader,\n",
    "                test_dl=test_loader,\n",
    "                CLASS_TO_ID=get_class_to_id(dataset)\n",
    "            )\n",
    "            \n",
    "            # Run training and get results\n",
    "            res = trainer.fit(args['epochs'])\n",
    "            \n",
    "            # Plotting the results\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.plot(np.arange(len(res[0])), res[0], label='train loss')\n",
    "            plt.plot(np.arange(len(res[1])), res[1], label='val loss')\n",
    "            plt.yscale('log')\n",
    "            plt.title('Training and Validation Loss')\n",
    "            plt.xlabel('Epochs')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'baseline_results/losses_{model_name}_{dataset}_{model_input}.svg')\n",
    "            plt.close()\n",
    "\n",
    "            print(\"Starting testing\")\n",
    "            test_res = trainer.test()\n",
    "            test_loss, _, accuracy, f1, recall = test_res\n",
    "            \n",
    "            result = {\n",
    "                'Model': model_name,\n",
    "                'Dataset': dataset,\n",
    "                'Input': model_input,\n",
    "                'Test Loss': test_loss,\n",
    "                'Accuracy': accuracy,\n",
    "                'F1-score': f1,\n",
    "                'Recall': recall\n",
    "            }\n",
    "            \n",
    "            # Append to results list\n",
    "            results.append(result)\n",
    "            \n",
    "            # Write the result to CSV\n",
    "            with open(csv_filename, 'w', newline='') as csvfile:\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=result.keys())\n",
    "                writer.writeheader()\n",
    "                writer.writerow(result)\n",
    "            \n",
    "            print(f\"Results saved for {model_name}, {dataset}, {model_input}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during experiment with {model_name}, {dataset}, {model_input}: {e}\")\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9e18fc0f-2a3f-4843-ad93-581be6d647b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with: {'batch_size': 32, 'epochs': 50, 'lr': 0.0001, 'w_decay': 1e-05, 'model_name': 'gru', 'dataset': 'aibo', 'model_input': 'mfcc'}\n",
      "Train: loss: 1.555769473976559\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 133, 1: 270, 2: 1779, 4: 10}\n",
      "Validation - Loss: 1.5653, Accuracy: 15.74%, Recall: 21.69%, F1-Score: 9.57%\n",
      "Validation loss decreased (inf --> 1.565259).  Saving model ...\n",
      "Train: loss: 1.4971117456754048\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1116, 1: 127, 2: 788, 3: 14, 4: 147}\n",
      "Validation - Loss: 1.4258, Accuracy: 46.72%, Recall: 36.27%, F1-Score: 43.05%\n",
      "Validation loss decreased (1.565259 --> 1.425769).  Saving model ...\n",
      "Train: loss: 1.4651621182759602\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1279, 1: 118, 2: 704, 3: 5, 4: 86}\n",
      "Validation - Loss: 1.3744, Accuracy: 50.09%, Recall: 36.46%, F1-Score: 44.79%\n",
      "Validation loss decreased (1.425769 --> 1.374449).  Saving model ...\n",
      "Train: loss: 1.4316261993514168\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1503, 1: 94, 2: 553, 3: 8, 4: 34}\n",
      "Validation - Loss: 1.2795, Accuracy: 52.87%, Recall: 34.60%, F1-Score: 45.24%\n",
      "Validation loss decreased (1.374449 --> 1.279546).  Saving model ...\n",
      "Train: loss: 1.4160456736882527\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1341, 1: 204, 2: 610, 3: 22, 4: 15}\n",
      "Validation - Loss: 1.3238, Accuracy: 50.27%, Recall: 35.23%, F1-Score: 44.21%\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Train: loss: 1.409554918607076\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1358, 1: 210, 2: 562, 3: 22, 4: 40}\n",
      "Validation - Loss: 1.2950, Accuracy: 51.09%, Recall: 34.62%, F1-Score: 45.70%\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Train: loss: 1.3588898234897189\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1387, 1: 154, 2: 610, 3: 6, 4: 35}\n",
      "Validation - Loss: 1.2766, Accuracy: 51.82%, Recall: 36.53%, F1-Score: 45.49%\n",
      "Validation loss decreased (1.279546 --> 1.276603).  Saving model ...\n",
      "Train: loss: 1.3793697198232016\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1422, 1: 131, 2: 573, 3: 29, 4: 37}\n",
      "Validation - Loss: 1.2512, Accuracy: 53.24%, Recall: 37.39%, F1-Score: 47.27%\n",
      "Validation loss decreased (1.276603 --> 1.251181).  Saving model ...\n",
      "Train: loss: 1.3592210398779976\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1562, 1: 64, 2: 511, 3: 2, 4: 53}\n",
      "Validation - Loss: 1.2088, Accuracy: 55.57%, Recall: 35.84%, F1-Score: 47.34%\n",
      "Validation loss decreased (1.251181 --> 1.208847).  Saving model ...\n",
      "Train: loss: 1.3550552950965034\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1583, 1: 57, 2: 464, 3: 43, 4: 45}\n",
      "Validation - Loss: 1.1832, Accuracy: 56.48%, Recall: 36.88%, F1-Score: 49.27%\n",
      "Validation loss decreased (1.208847 --> 1.183217).  Saving model ...\n",
      "Train: loss: 1.3484458221329583\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1408, 1: 132, 2: 508, 3: 69, 4: 75}\n",
      "Validation - Loss: 1.2288, Accuracy: 56.16%, Recall: 40.29%, F1-Score: 51.77%\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Train: loss: 1.341578435897827\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1382, 1: 81, 2: 599, 3: 96, 4: 34}\n",
      "Validation - Loss: 1.2241, Accuracy: 54.61%, Recall: 38.33%, F1-Score: 49.76%\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Train: loss: 1.325326104958852\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1559, 1: 70, 2: 476, 3: 32, 4: 55}\n",
      "Validation - Loss: 1.1749, Accuracy: 56.39%, Recall: 37.77%, F1-Score: 49.38%\n",
      "Validation loss decreased (1.183217 --> 1.174900).  Saving model ...\n",
      "Train: loss: 1.3119555897182889\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1600, 1: 90, 2: 365, 3: 58, 4: 79}\n",
      "Validation - Loss: 1.1594, Accuracy: 58.49%, Recall: 39.00%, F1-Score: 52.42%\n",
      "Validation loss decreased (1.174900 --> 1.159440).  Saving model ...\n",
      "Train: loss: 1.312093162536621\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1541, 1: 67, 2: 452, 3: 56, 4: 76}\n",
      "Validation - Loss: 1.1382, Accuracy: 57.66%, Recall: 39.03%, F1-Score: 51.59%\n",
      "Validation loss decreased (1.159440 --> 1.138204).  Saving model ...\n",
      "Train: loss: 1.2959837542639838\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1588, 1: 25, 2: 457, 3: 65, 4: 57}\n",
      "Validation - Loss: 1.1440, Accuracy: 57.30%, Recall: 37.90%, F1-Score: 50.36%\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Train: loss: 1.3003728959295484\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1522, 1: 45, 2: 521, 3: 30, 4: 74}\n",
      "Validation - Loss: 1.1559, Accuracy: 56.48%, Recall: 38.72%, F1-Score: 49.60%\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Train: loss: 1.291069663895501\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1565, 1: 69, 2: 435, 3: 50, 4: 73}\n",
      "Validation - Loss: 1.1444, Accuracy: 57.66%, Recall: 38.48%, F1-Score: 51.30%\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Train: loss: 1.28979611992836\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1343, 1: 95, 2: 557, 3: 140, 4: 57}\n",
      "Validation - Loss: 1.1931, Accuracy: 55.84%, Recall: 42.01%, F1-Score: 52.19%\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Train: loss: 1.2733539634280735\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1589, 1: 23, 2: 476, 3: 52, 4: 52}\n",
      "Validation - Loss: 1.1312, Accuracy: 57.12%, Recall: 37.72%, F1-Score: 49.72%\n",
      "Validation loss decreased (1.138204 --> 1.131191).  Saving model ...\n",
      "Train: loss: 1.2796674503220453\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1453, 1: 58, 2: 419, 3: 205, 4: 57}\n",
      "Validation - Loss: 1.1441, Accuracy: 56.71%, Recall: 39.59%, F1-Score: 52.28%\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Train: loss: 1.2600084867742327\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1374, 1: 40, 2: 514, 3: 189, 4: 75}\n",
      "Validation - Loss: 1.1472, Accuracy: 56.75%, Recall: 41.24%, F1-Score: 52.79%\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Train: loss: 1.2473652925756242\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1315, 1: 120, 2: 613, 3: 40, 4: 104}\n",
      "Validation - Loss: 1.2008, Accuracy: 55.11%, Recall: 41.73%, F1-Score: 50.67%\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Train: loss: 1.2355236132939658\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1307, 1: 85, 2: 652, 3: 73, 4: 75}\n",
      "Validation - Loss: 1.2135, Accuracy: 54.15%, Recall: 40.10%, F1-Score: 49.80%\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Train: loss: 1.23101729883088\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1399, 1: 78, 2: 438, 3: 126, 4: 151}\n",
      "Validation - Loss: 1.1084, Accuracy: 59.17%, Recall: 44.28%, F1-Score: 55.80%\n",
      "Validation loss decreased (1.131191 --> 1.108432).  Saving model ...\n",
      "Train: loss: 1.237309416135152\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1251, 1: 78, 2: 575, 3: 173, 4: 115}\n",
      "Validation - Loss: 1.1491, Accuracy: 56.25%, Recall: 43.23%, F1-Score: 53.72%\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Train: loss: 1.232624265882704\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1419, 1: 56, 2: 509, 3: 131, 4: 77}\n",
      "Validation - Loss: 1.1403, Accuracy: 57.21%, Recall: 41.40%, F1-Score: 52.73%\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Train: loss: 1.2321882949935066\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1251, 1: 67, 2: 616, 3: 160, 4: 98}\n",
      "Validation - Loss: 1.1701, Accuracy: 55.66%, Recall: 43.02%, F1-Score: 52.81%\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Train: loss: 1.219937190744612\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1476, 1: 63, 2: 393, 3: 196, 4: 64}\n",
      "Validation - Loss: 1.1077, Accuracy: 58.03%, Recall: 41.07%, F1-Score: 53.73%\n",
      "Validation loss decreased (1.108432 --> 1.107696).  Saving model ...\n",
      "Train: loss: 1.2109190821647644\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1309, 1: 89, 2: 545, 3: 156, 4: 93}\n",
      "Validation - Loss: 1.1423, Accuracy: 56.07%, Recall: 42.57%, F1-Score: 52.94%\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Train: loss: 1.2105183117919498\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1406, 1: 132, 2: 366, 3: 197, 4: 91}\n",
      "Validation - Loss: 1.0996, Accuracy: 59.31%, Recall: 44.33%, F1-Score: 56.55%\n",
      "Validation loss decreased (1.107696 --> 1.099555).  Saving model ...\n",
      "Train: loss: 1.201273379723231\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1241, 1: 99, 2: 464, 3: 301, 4: 87}\n",
      "Validation - Loss: 1.1224, Accuracy: 56.25%, Recall: 44.47%, F1-Score: 54.33%\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Train: loss: 1.1873895254400042\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1345, 1: 54, 2: 502, 3: 223, 4: 68}\n",
      "Validation - Loss: 1.1245, Accuracy: 56.93%, Recall: 42.65%, F1-Score: 53.50%\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Train: loss: 1.1881530317995284\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1286, 1: 106, 2: 502, 3: 186, 4: 112}\n",
      "Validation - Loss: 1.1394, Accuracy: 56.66%, Recall: 43.72%, F1-Score: 54.29%\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Train: loss: 1.1833522730403476\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1296, 1: 95, 2: 483, 3: 228, 4: 90}\n",
      "Validation - Loss: 1.1150, Accuracy: 57.39%, Recall: 44.13%, F1-Score: 54.73%\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Train: loss: 1.1862045281463198\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1325, 1: 124, 2: 466, 3: 163, 4: 114}\n",
      "Validation - Loss: 1.1062, Accuracy: 57.85%, Recall: 44.83%, F1-Score: 55.16%\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Train: loss: 1.1903631183836194\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1252, 1: 101, 2: 533, 3: 190, 4: 116}\n",
      "Validation - Loss: 1.1242, Accuracy: 56.89%, Recall: 45.29%, F1-Score: 54.67%\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Train: loss: 1.1758627785576714\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1275, 1: 103, 2: 499, 3: 181, 4: 134}\n",
      "Validation - Loss: 1.1046, Accuracy: 57.94%, Recall: 46.13%, F1-Score: 55.69%\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Train: loss: 1.1666866229640114\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1202, 1: 144, 2: 524, 3: 210, 4: 112}\n",
      "Validation - Loss: 1.1436, Accuracy: 55.57%, Recall: 44.85%, F1-Score: 53.97%\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Train: loss: 1.1590363058778974\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1365, 1: 115, 2: 426, 3: 212, 4: 74}\n",
      "Validation - Loss: 1.1130, Accuracy: 57.66%, Recall: 43.43%, F1-Score: 54.59%\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Train: loss: 1.1663349250952402\n",
      "True label distribution: {0: 1154, 1: 153, 2: 267, 3: 348, 4: 270}\n",
      "Predicted label distribution: {0: 1236, 1: 101, 2: 521, 3: 252, 4: 82}\n",
      "Validation - Loss: 1.1380, Accuracy: 55.75%, Recall: 44.28%, F1-Score: 53.48%\n",
      "EarlyStopping counter: 10 out of 10\n",
      "EarlyStopping counter is higher than patience\n",
      "Early stopping has been reached\n",
      "Starting testing\n",
      "True label distribution: {0: 2033, 1: 250, 2: 152, 3: 581, 4: 333}\n",
      "Predicted label distribution: {0: 1900, 1: 203, 2: 485, 3: 643, 4: 118}\n",
      "Test - Loss: 1.1368, Accuracy: 53.69%, Recall: 42.67%, F1-Score: 54.51%\n",
      "Results saved for gru, aibo, mfcc\n",
      "Skipping experiment with: gru, aibo, mspc (CSV file already exists)\n",
      "Skipping experiment with: cnn, aibo, mfcc (CSV file already exists)\n",
      "Skipping experiment with: cnn, aibo, mspc (CSV file already exists)\n"
     ]
    }
   ],
   "source": [
    "base_args = {\n",
    "    'batch_size': 32,\n",
    "    'epochs': 50,\n",
    "    'lr': 0.0001,\n",
    "    'w_decay': 0.00001,\n",
    "    # Other necessary args for Trainer\n",
    "}\n",
    "\n",
    "# Run combined experiments\n",
    "results_df_aibo = run_combined_experiments_aibo(base_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6feb0ad8-3575-4b1a-a4ff-80ad01ca76b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Input</th>\n",
       "      <th>Test Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gru</td>\n",
       "      <td>aibo</td>\n",
       "      <td>mfcc</td>\n",
       "      <td>1.136803</td>\n",
       "      <td>0.536877</td>\n",
       "      <td>0.389078</td>\n",
       "      <td>0.426693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Dataset Input  Test Loss  Accuracy  F1-score    Recall\n",
       "0   gru    aibo  mfcc   1.136803  0.536877  0.389078  0.426693"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(results_df_aibo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "72b69eac-5941-427b-809f-ffde4e286989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'gru', 'Dataset': 'aibo', 'Input': 'mspc', 'Test Loss': '1.5126313338284012', 'Accuracy': '0.3744049180942385', 'F1-score': '0.3421639446380046', 'Recall': '0.45521637036390344'}\n"
     ]
    }
   ],
   "source": [
    "with open(\"baseline_results/experiment_results_gru_aibo_mspc.csv\", 'r', newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ae54db8d-bc5d-4208-90a6-5276fcc3b4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'cnn', 'Dataset': 'aibo', 'Input': 'mspc', 'Test Loss': '1.58825683951092', 'Accuracy': '0.39157326535967313', 'F1-score': '0.38420010001541416', 'Recall': '0.5509646535754402'}\n"
     ]
    }
   ],
   "source": [
    "with open(\"baseline_results/experiment_results_cnn_aibo_mspc.csv\", 'r', newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5cfcdcb6-8d89-4ea3-9855-8593c7d5501b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'cnn', 'Dataset': 'aibo', 'Input': 'mfcc', 'Test Loss': '1.1807345594678607', 'Accuracy': '0.5100029859659599', 'F1-score': '0.3866879662853459', 'Recall': '0.4337179647470558'}\n"
     ]
    }
   ],
   "source": [
    "with open(\"baseline_results/experiment_results_cnn_aibo_mfcc.csv\", 'r', newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc39f5be-9c8d-4791-bd9c-ec1a3aa935e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "89911356-3231-477f-b9b7-c536a76794ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_combined_experiments_icp(base_args):\n",
    "    results = []\n",
    "    \n",
    "    model_names = ['gru', 'cnn']\n",
    "    datasets = ['iemocap']\n",
    "    model_inputs = ['mfcc', 'mspc']\n",
    "\n",
    "    for model_name, dataset, model_input in product(model_names, datasets, model_inputs):\n",
    "        # Create a unique filename for this specific combination\n",
    "        csv_filename = f\"baseline_results/experiment_results_{model_name}_{dataset}_{model_input}.csv\"\n",
    "        \n",
    "        # If the CSV file already exists, skip this experiment\n",
    "        if os.path.isfile(csv_filename):\n",
    "            print(f\"Skipping experiment with: {model_name}, {dataset}, {model_input} (CSV file already exists)\")\n",
    "            continue\n",
    "\n",
    "        args = {**base_args, 'model_name': model_name, 'dataset': dataset, 'model_input': model_input}\n",
    "\n",
    "        try:\n",
    "            print(f\"Running experiment with: {args}\")\n",
    "            \n",
    "            # Initialize device\n",
    "            device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")\n",
    "            \n",
    "            # Load data\n",
    "            train_loader, val_loader, test_loader = get_data_loaders(args)\n",
    "            \n",
    "            # Initialize model based on the configuration\n",
    "            if model_name == 'cnn':\n",
    "                if model_input == 'mfcc':\n",
    "                    model = CNN(n_classes=5, dur=MFCC_DUR, numcep=NUMCEP, input_type=\"mfcc\",\n",
    "                                kernel1=(3,3), kernel2=(2,2)).to(device)\n",
    "                else:  # mspc\n",
    "                    model = CNN(n_classes=5, dur=50, numcep=SPECTR_DUR, input_type=\"mspc\",\n",
    "                                kernel1=(3,3), kernel2=(2,2)).to(device)\n",
    "            elif model_name == 'gru':\n",
    "                if model_input == 'mfcc':\n",
    "                    model = Conv_GRU(\n",
    "                        input_shape=[args['batch_size'], 1, NUMCEP, MFCC_DUR], \n",
    "                        hidden_size=32, \n",
    "                        kernel1=(3, 3), \n",
    "                        kernel2=(2, 2)).to(device)\n",
    "                else:\n",
    "                    model = Conv_GRU(\n",
    "                        input_shape=[args['batch_size'], 1, SPECTR_DUR, MFCC_DUR], \n",
    "                        hidden_size=32, \n",
    "                        kernel1=(3, 3), \n",
    "                        kernel2=(2, 2)).to(device)\n",
    "\n",
    "            # Setup optimizer and loss function\n",
    "            optimizer = Adam(model.parameters(), lr=args['lr'], weight_decay=args['w_decay'])\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            \n",
    "            # Create an instance of Trainer\n",
    "            trainer = Trainer(\n",
    "                model=model,\n",
    "                model_name=model_name,\n",
    "                dataset=dataset,\n",
    "                crit=criterion,\n",
    "                optim=optimizer,\n",
    "                train_dl=train_loader,\n",
    "                val_test_dl=val_loader,\n",
    "                test_dl=test_loader,\n",
    "                CLASS_TO_ID=get_class_to_id(dataset)\n",
    "            )\n",
    "            \n",
    "            # Run training and get results\n",
    "            res = trainer.fit(args['epochs'])\n",
    "            \n",
    "            # Plotting the results\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.plot(np.arange(len(res[0])), res[0], label='train loss')\n",
    "            plt.plot(np.arange(len(res[1])), res[1], label='val loss')\n",
    "            plt.yscale('log')\n",
    "            plt.title('Training and Validation Loss')\n",
    "            plt.xlabel('Epochs')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'baseline_results/losses_{model_name}_{dataset}_{model_input}.svg')\n",
    "            plt.close()\n",
    "\n",
    "            print(\"Starting testing\")\n",
    "            test_res = trainer.test()\n",
    "            test_loss, _, accuracy, f1, recall = test_res\n",
    "            \n",
    "            result = {\n",
    "                'Model': model_name,\n",
    "                'Dataset': dataset,\n",
    "                'Input': model_input,\n",
    "                'Test Loss': test_loss,\n",
    "                'Accuracy': accuracy,\n",
    "                'F1-score': f1,\n",
    "                'Recall': recall\n",
    "            }\n",
    "            \n",
    "            # Append to results list\n",
    "            results.append(result)\n",
    "            \n",
    "            # Write the result to CSV\n",
    "            with open(csv_filename, 'w', newline='') as csvfile:\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=result.keys())\n",
    "                writer.writeheader()\n",
    "                writer.writerow(result)\n",
    "            \n",
    "            print(f\"Results saved for {model_name}, {dataset}, {model_input}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during experiment with {model_name}, {dataset}, {model_input}: {e}\")\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63131de1-e5c6-4b51-b643-389a615b9401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with: {'batch_size': 32, 'epochs': 100, 'lr': 0.0001, 'w_decay': 1e-05, 'model_name': 'gru', 'dataset': 'iemocap', 'model_input': 'mfcc'}\n",
      "Train: loss: 1.4006815869378555\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 1683, 1: 1330, 2: 7754, 3: 5140, 4: 1892}\n",
      "Validation - Loss: 1.3965, Accuracy: 37.03%, Recall: 40.00%, F1-Score: 32.50%\n",
      "Validation loss decreased (inf --> 1.396523).  Saving model ...\n",
      "Train: loss: 1.3363637642588824\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 747, 1: 1561, 2: 8666, 3: 5514, 4: 1311}\n",
      "Validation - Loss: 1.3997, Accuracy: 36.93%, Recall: 39.09%, F1-Score: 31.37%\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Train: loss: 1.3150039038070445\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 1909, 1: 1564, 2: 6129, 3: 5203, 4: 2994}\n",
      "Validation - Loss: 1.3963, Accuracy: 39.04%, Recall: 43.16%, F1-Score: 35.41%\n",
      "Validation loss decreased (1.396523 --> 1.396282).  Saving model ...\n",
      "Train: loss: 1.3015128129781905\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 682, 1: 1992, 2: 5431, 3: 6750, 4: 2944}\n",
      "Validation - Loss: 1.4195, Accuracy: 37.87%, Recall: 41.88%, F1-Score: 33.03%\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Train: loss: 1.285355116528512\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 725, 1: 2648, 2: 6545, 3: 4896, 4: 2985}\n",
      "Validation - Loss: 1.4120, Accuracy: 38.42%, Recall: 43.46%, F1-Score: 33.38%\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Train: loss: 1.274486592949049\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 997, 1: 1757, 2: 5570, 3: 6028, 4: 3447}\n",
      "Validation - Loss: 1.4262, Accuracy: 38.31%, Recall: 43.51%, F1-Score: 33.53%\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Train: loss: 1.2672245084515918\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 1610, 1: 1846, 2: 8388, 3: 4481, 4: 1474}\n",
      "Validation - Loss: 1.4111, Accuracy: 37.74%, Recall: 40.18%, F1-Score: 33.83%\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Train: loss: 1.261735689517608\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 1244, 1: 1897, 2: 6782, 3: 5933, 4: 1943}\n",
      "Validation - Loss: 1.3928, Accuracy: 39.34%, Recall: 42.04%, F1-Score: 35.10%\n",
      "Validation loss decreased (1.396282 --> 1.392836).  Saving model ...\n",
      "Train: loss: 1.2538716568777653\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 1334, 1: 2813, 2: 6876, 3: 4943, 4: 1833}\n",
      "Validation - Loss: 1.3857, Accuracy: 39.65%, Recall: 42.69%, F1-Score: 35.96%\n",
      "Validation loss decreased (1.392836 --> 1.385673).  Saving model ...\n",
      "Train: loss: 1.2473755308559962\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 758, 1: 2710, 2: 4577, 3: 4822, 4: 4932}\n",
      "Validation - Loss: 1.5298, Accuracy: 35.79%, Recall: 41.90%, F1-Score: 32.42%\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Train: loss: 1.240166639580446\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 2036, 1: 2333, 2: 6591, 3: 3809, 4: 3030}\n",
      "Validation - Loss: 1.4133, Accuracy: 38.97%, Recall: 43.45%, F1-Score: 35.85%\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Train: loss: 1.2353978612843681\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 1350, 1: 2535, 2: 6320, 3: 5369, 4: 2225}\n",
      "Validation - Loss: 1.3951, Accuracy: 40.24%, Recall: 43.36%, F1-Score: 36.84%\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Train: loss: 1.2341818244628657\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 1615, 1: 2881, 2: 6579, 3: 4820, 4: 1904}\n",
      "Validation - Loss: 1.3863, Accuracy: 40.57%, Recall: 43.37%, F1-Score: 37.57%\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Train: loss: 1.2237831977457783\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 2521, 1: 3622, 2: 6569, 3: 3924, 4: 1163}\n",
      "Validation - Loss: 1.3569, Accuracy: 41.12%, Recall: 42.27%, F1-Score: 39.02%\n",
      "Validation loss decreased (1.385673 --> 1.356934).  Saving model ...\n",
      "Train: loss: 1.2201458542954688\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 2304, 1: 2337, 2: 6820, 3: 4410, 4: 1928}\n",
      "Validation - Loss: 1.3861, Accuracy: 41.12%, Recall: 43.89%, F1-Score: 38.42%\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Train: loss: 1.2180451848705054\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 1914, 1: 3512, 2: 4997, 3: 4089, 4: 3287}\n",
      "Validation - Loss: 1.3936, Accuracy: 40.75%, Recall: 45.25%, F1-Score: 38.62%\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Train: loss: 1.2147431785430338\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 1803, 1: 4096, 2: 3468, 3: 4493, 4: 3939}\n",
      "Validation - Loss: 1.4464, Accuracy: 37.96%, Recall: 42.90%, F1-Score: 36.82%\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Train: loss: 1.2080958955316874\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 2848, 1: 2826, 2: 6273, 3: 4131, 4: 1721}\n",
      "Validation - Loss: 1.3717, Accuracy: 41.74%, Recall: 43.70%, F1-Score: 39.83%\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Train: loss: 1.2026172923663305\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 2343, 1: 3237, 2: 6077, 3: 4201, 4: 1941}\n",
      "Validation - Loss: 1.3948, Accuracy: 40.70%, Recall: 42.94%, F1-Score: 38.65%\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Train: loss: 1.1973770134477946\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 2424, 1: 3382, 2: 5923, 3: 4403, 4: 1667}\n",
      "Validation - Loss: 1.3564, Accuracy: 41.75%, Recall: 43.65%, F1-Score: 39.81%\n",
      "Validation loss decreased (1.356934 --> 1.356355).  Saving model ...\n",
      "Train: loss: 1.1907103175208682\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 3008, 1: 3464, 2: 5630, 3: 3255, 4: 2442}\n",
      "Validation - Loss: 1.3510, Accuracy: 42.68%, Recall: 46.17%, F1-Score: 40.76%\n",
      "Validation loss decreased (1.356355 --> 1.351015).  Saving model ...\n",
      "Train: loss: 1.1905796838964289\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 1627, 1: 3585, 2: 6483, 3: 4681, 4: 1423}\n",
      "Validation - Loss: 1.3926, Accuracy: 39.92%, Recall: 41.83%, F1-Score: 37.24%\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Train: loss: 1.1839535925902573\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 2389, 1: 3218, 2: 5950, 3: 4131, 4: 2111}\n",
      "Validation - Loss: 1.3791, Accuracy: 41.05%, Recall: 43.52%, F1-Score: 39.05%\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Train: loss: 1.1808136116668067\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 2281, 1: 3160, 2: 6051, 3: 4625, 4: 1682}\n",
      "Validation - Loss: 1.3610, Accuracy: 41.87%, Recall: 43.83%, F1-Score: 39.77%\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Train: loss: 1.174897503285181\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 2768, 1: 3188, 2: 6016, 3: 4349, 4: 1478}\n",
      "Validation - Loss: 1.3590, Accuracy: 42.33%, Recall: 43.88%, F1-Score: 40.56%\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Train: loss: 1.1745626850177149\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 2505, 1: 3620, 2: 5809, 3: 3719, 4: 2146}\n",
      "Validation - Loss: 1.3603, Accuracy: 41.89%, Recall: 44.69%, F1-Score: 39.93%\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Train: loss: 1.1708332255663547\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 2571, 1: 3839, 2: 4302, 3: 4498, 4: 2589}\n",
      "Validation - Loss: 1.3733, Accuracy: 41.88%, Recall: 45.14%, F1-Score: 40.77%\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Train: loss: 1.1671483947449373\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 1681, 1: 3548, 2: 5333, 3: 4764, 4: 2473}\n",
      "Validation - Loss: 1.3885, Accuracy: 41.76%, Recall: 45.17%, F1-Score: 39.39%\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Train: loss: 1.1632865556593146\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 2906, 1: 3063, 2: 6713, 3: 3655, 4: 1462}\n",
      "Validation - Loss: 1.3757, Accuracy: 41.05%, Recall: 42.60%, F1-Score: 38.97%\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Train: loss: 1.162275517855038\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 2065, 1: 3689, 2: 6298, 3: 3747, 4: 2000}\n",
      "Validation - Loss: 1.3900, Accuracy: 41.21%, Recall: 43.76%, F1-Score: 38.86%\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Train: loss: 1.1553817941806341\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 3130, 1: 3091, 2: 6048, 3: 4139, 4: 1391}\n",
      "Validation - Loss: 1.3772, Accuracy: 42.19%, Recall: 43.27%, F1-Score: 40.60%\n",
      "EarlyStopping counter: 10 out of 10\n",
      "EarlyStopping counter is higher than patience\n",
      "Early stopping has been reached\n",
      "Starting testing\n",
      "True label distribution: {0: 2406, 1: 3717, 2: 2871, 3: 6516, 4: 3603}\n",
      "Predicted label distribution: {0: 2888, 1: 1918, 2: 4612, 3: 5258, 4: 4437}\n",
      "Test - Loss: 1.3855, Accuracy: 40.51%, Recall: 41.67%, F1-Score: 38.97%\n",
      "Results saved for gru, iemocap, mfcc\n",
      "Running experiment with: {'batch_size': 32, 'epochs': 100, 'lr': 0.0001, 'w_decay': 1e-05, 'model_name': 'gru', 'dataset': 'iemocap', 'model_input': 'mspc'}\n",
      "True label distribution: {0: 17802, 1: 15702, 2: 12963, 3: 16998, 4: 6513}\n",
      "Predicted label distribution: {0: 17390, 1: 7228, 2: 34511, 3: 5330, 4: 5519}\n",
      "Validation - Loss: 1.5253, Accuracy: 30.61%, Recall: 32.37%, F1-Score: 27.00%\n",
      "Validation loss decreased (inf --> 1.525349).  Saving model ...\n",
      "Train: loss: 1.3358418242159216\n",
      "True label distribution: {0: 17802, 1: 15702, 2: 12963, 3: 16998, 4: 6513}\n",
      "Predicted label distribution: {0: 13359, 1: 15212, 2: 30220, 3: 6379, 4: 4808}\n",
      "Validation - Loss: 1.4443, Accuracy: 35.06%, Recall: 36.64%, F1-Score: 32.25%\n",
      "Validation loss decreased (1.484854 --> 1.444291).  Saving model ...\n",
      "Train: loss: 1.3182607722525117\n",
      "True label distribution: {0: 17802, 1: 15702, 2: 12963, 3: 16998, 4: 6513}\n",
      "Predicted label distribution: {0: 15588, 1: 19285, 2: 23772, 3: 7418, 4: 3915}\n",
      "Validation - Loss: 1.3977, Accuracy: 37.15%, Recall: 37.99%, F1-Score: 34.91%\n",
      "Validation loss decreased (1.444291 --> 1.397677).  Saving model ...\n",
      "Train: loss: 1.3042549285332137\n",
      "True label distribution: {0: 17802, 1: 15702, 2: 12963, 3: 16998, 4: 6513}\n",
      "Predicted label distribution: {0: 12488, 1: 16072, 2: 28555, 3: 8688, 4: 4175}\n",
      "Validation - Loss: 1.4236, Accuracy: 36.43%, Recall: 37.82%, F1-Score: 34.15%\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Train: loss: 1.291187261428797\n",
      "True label distribution: {0: 17802, 1: 15702, 2: 12963, 3: 16998, 4: 6513}\n",
      "Predicted label distribution: {0: 17704, 1: 15149, 2: 23314, 3: 10365, 4: 3446}\n",
      "Validation - Loss: 1.4159, Accuracy: 37.22%, Recall: 37.56%, F1-Score: 35.69%\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Train: loss: 1.2820810766777757\n",
      "True label distribution: {0: 17802, 1: 15702, 2: 12963, 3: 16998, 4: 6513}\n",
      "Predicted label distribution: {0: 14409, 1: 17958, 2: 22307, 3: 11122, 4: 4182}\n",
      "Validation - Loss: 1.4133, Accuracy: 37.49%, Recall: 38.32%, F1-Score: 36.06%\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Train: loss: 1.27397266483273\n",
      "True label distribution: {0: 17802, 1: 15702, 2: 12963, 3: 16998, 4: 6513}\n",
      "Predicted label distribution: {0: 9472, 1: 16932, 2: 23764, 3: 13420, 4: 6390}\n",
      "Validation - Loss: 1.4095, Accuracy: 37.61%, Recall: 39.97%, F1-Score: 35.73%\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Train: loss: 1.2637915449837844\n",
      "True label distribution: {0: 17802, 1: 15702, 2: 12963, 3: 16998, 4: 6513}\n",
      "Predicted label distribution: {0: 7432, 1: 15478, 2: 21730, 3: 16350, 4: 8988}\n",
      "Validation - Loss: 1.4336, Accuracy: 37.30%, Recall: 40.43%, F1-Score: 35.27%\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Train: loss: 1.2573287408714267\n",
      "True label distribution: {0: 17802, 1: 15702, 2: 12963, 3: 16998, 4: 6513}\n",
      "Predicted label distribution: {0: 16211, 1: 18355, 2: 23335, 3: 9460, 4: 2617}\n",
      "Validation - Loss: 1.4215, Accuracy: 37.33%, Recall: 37.27%, F1-Score: 35.41%\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Train: loss: 1.2497348708354614\n",
      "True label distribution: {0: 17802, 1: 15702, 2: 12963, 3: 16998, 4: 6513}\n",
      "Predicted label distribution: {0: 11774, 1: 16025, 2: 23721, 3: 12846, 4: 5612}\n",
      "Validation - Loss: 1.4224, Accuracy: 37.84%, Recall: 39.59%, F1-Score: 36.25%\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Train: loss: 1.2429352822911106\n",
      "True label distribution: {0: 17802, 1: 15702, 2: 12963, 3: 16998, 4: 6513}\n",
      "Predicted label distribution: {0: 13639, 1: 17527, 2: 20858, 3: 14462, 4: 3492}\n",
      "Validation - Loss: 1.4111, Accuracy: 38.03%, Recall: 38.33%, F1-Score: 36.92%\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Train: loss: 1.2358332342665754\n",
      "True label distribution: {0: 17802, 1: 15702, 2: 12963, 3: 16998, 4: 6513}\n",
      "Predicted label distribution: {0: 7801, 1: 15569, 2: 19460, 3: 19561, 4: 7587}\n",
      "Validation - Loss: 1.4304, Accuracy: 37.64%, Recall: 39.95%, F1-Score: 36.06%\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Train: loss: 1.229361494001227\n",
      "True label distribution: {0: 17802, 1: 15702, 2: 12963, 3: 16998, 4: 6513}\n",
      "Predicted label distribution: {0: 14286, 1: 16817, 2: 22867, 3: 10919, 4: 5089}\n",
      "Validation - Loss: 1.4260, Accuracy: 37.85%, Recall: 39.27%, F1-Score: 36.29%\n",
      "EarlyStopping counter: 10 out of 10\n",
      "EarlyStopping counter is higher than patience\n",
      "Early stopping has been reached\n",
      "Starting testing\n",
      "True label distribution: {0: 10212, 1: 14817, 2: 10566, 3: 25503, 4: 14637}\n",
      "Predicted label distribution: {0: 16341, 1: 21128, 2: 14740, 3: 12013, 4: 11513}\n",
      "Test - Loss: 1.4819, Accuracy: 33.20%, Recall: 36.42%, F1-Score: 32.88%\n",
      "Results saved for gru, iemocap, mspc\n",
      "Running experiment with: {'batch_size': 32, 'epochs': 100, 'lr': 0.0001, 'w_decay': 1e-05, 'model_name': 'cnn', 'dataset': 'iemocap', 'model_input': 'mfcc'}\n",
      "Train: loss: 1.4157258008374554\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 3152, 1: 1838, 2: 8363, 3: 3402, 4: 1044}\n",
      "Validation - Loss: 1.3971, Accuracy: 37.39%, Recall: 38.51%, F1-Score: 34.19%\n",
      "Validation loss decreased (inf --> 1.397085).  Saving model ...\n",
      "Train: loss: 1.3338221486876993\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 1884, 1: 2847, 2: 4172, 3: 5010, 4: 3886}\n",
      "Validation - Loss: 1.4061, Accuracy: 37.42%, Recall: 43.07%, F1-Score: 35.22%\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Train: loss: 1.3171508719607228\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 2385, 1: 2189, 2: 4296, 3: 5693, 4: 3236}\n",
      "Validation - Loss: 1.3859, Accuracy: 38.48%, Recall: 43.04%, F1-Score: 36.37%\n",
      "Validation loss decreased (1.397085 --> 1.385939).  Saving model ...\n",
      "Train: loss: 1.3050236576188958\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 2237, 1: 2576, 2: 5162, 3: 5265, 4: 2559}\n",
      "Validation - Loss: 1.3635, Accuracy: 39.67%, Recall: 43.47%, F1-Score: 37.31%\n",
      "Validation loss decreased (1.385939 --> 1.363475).  Saving model ...\n",
      "Train: loss: 1.2960469209068184\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 2436, 1: 1591, 2: 5794, 3: 6200, 4: 1778}\n",
      "Validation - Loss: 1.3568, Accuracy: 40.03%, Recall: 42.28%, F1-Score: 36.91%\n",
      "Validation loss decreased (1.363475 --> 1.356763).  Saving model ...\n",
      "Train: loss: 1.2888099798857888\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 2950, 1: 2058, 2: 4725, 3: 5672, 4: 2394}\n",
      "Validation - Loss: 1.3529, Accuracy: 40.39%, Recall: 43.65%, F1-Score: 38.31%\n",
      "Validation loss decreased (1.356763 --> 1.352857).  Saving model ...\n",
      "Train: loss: 1.278246300449781\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 3287, 1: 1449, 2: 5152, 3: 6145, 4: 1766}\n",
      "Validation - Loss: 1.3459, Accuracy: 41.37%, Recall: 43.48%, F1-Score: 38.73%\n",
      "Validation loss decreased (1.352857 --> 1.345907).  Saving model ...\n",
      "Train: loss: 1.2725203914913923\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 3336, 1: 1717, 2: 5909, 3: 5473, 4: 1364}\n",
      "Validation - Loss: 1.3446, Accuracy: 41.61%, Recall: 43.07%, F1-Score: 39.07%\n",
      "Validation loss decreased (1.345907 --> 1.344628).  Saving model ...\n",
      "Train: loss: 1.2631995577772124\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 2794, 1: 2179, 2: 5461, 3: 5104, 4: 2261}\n",
      "Validation - Loss: 1.3503, Accuracy: 40.88%, Recall: 44.06%, F1-Score: 38.53%\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Train: loss: 1.2600065220971735\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 3113, 1: 2683, 2: 3964, 3: 6208, 4: 1831}\n",
      "Validation - Loss: 1.3570, Accuracy: 40.97%, Recall: 42.54%, F1-Score: 39.96%\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Train: loss: 1.2578846469980662\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 2147, 1: 3333, 2: 4696, 3: 5040, 4: 2583}\n",
      "Validation - Loss: 1.3675, Accuracy: 40.18%, Recall: 43.71%, F1-Score: 38.22%\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Train: loss: 1.2480408599953245\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 3358, 1: 1853, 2: 6513, 3: 4958, 4: 1117}\n",
      "Validation - Loss: 1.3487, Accuracy: 41.01%, Recall: 41.92%, F1-Score: 38.51%\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Train: loss: 1.2445281512485722\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 2490, 1: 3039, 2: 5260, 3: 4942, 4: 2068}\n",
      "Validation - Loss: 1.3536, Accuracy: 41.08%, Recall: 44.03%, F1-Score: 39.04%\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Train: loss: 1.2412669142198607\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 2787, 1: 2727, 2: 5660, 3: 4127, 4: 2498}\n",
      "Validation - Loss: 1.3541, Accuracy: 41.09%, Recall: 44.95%, F1-Score: 38.82%\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Train: loss: 1.2328429044016491\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 1463, 1: 3404, 2: 5553, 3: 5099, 4: 2280}\n",
      "Validation - Loss: 1.3685, Accuracy: 40.83%, Recall: 44.50%, F1-Score: 37.73%\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Train: loss: 1.2277385590791035\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 2366, 1: 3405, 2: 5003, 3: 4497, 4: 2528}\n",
      "Validation - Loss: 1.3658, Accuracy: 40.78%, Recall: 44.38%, F1-Score: 38.84%\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Train: loss: 1.2279641778529191\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 2023, 1: 4012, 2: 5148, 3: 5030, 4: 1586}\n",
      "Validation - Loss: 1.3463, Accuracy: 41.49%, Recall: 43.73%, F1-Score: 39.38%\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Train: loss: 1.2193126384617567\n",
      "True label distribution: {0: 4458, 1: 3930, 2: 3435, 3: 4359, 4: 1617}\n",
      "Predicted label distribution: {0: 2792, 1: 2808, 2: 4882, 3: 4875, 4: 2442}\n",
      "Validation - Loss: 1.3551, Accuracy: 40.83%, Recall: 44.21%, F1-Score: 39.00%\n",
      "EarlyStopping counter: 10 out of 10\n",
      "EarlyStopping counter is higher than patience\n",
      "Early stopping has been reached\n",
      "Starting testing\n",
      "True label distribution: {0: 2406, 1: 3717, 2: 2871, 3: 6516, 4: 3603}\n",
      "Predicted label distribution: {0: 2504, 1: 1250, 2: 3703, 3: 5354, 4: 6302}\n",
      "Test - Loss: 1.3416, Accuracy: 41.09%, Recall: 41.99%, F1-Score: 38.27%\n",
      "Results saved for cnn, iemocap, mfcc\n",
      "Running experiment with: {'batch_size': 32, 'epochs': 100, 'lr': 0.0001, 'w_decay': 1e-05, 'model_name': 'cnn', 'dataset': 'iemocap', 'model_input': 'mspc'}\n",
      "Train: loss: 1.4123457770681742\n",
      "True label distribution: {0: 17802, 1: 15702, 2: 12963, 3: 16998, 4: 6513}\n",
      "Predicted label distribution: {0: 9599, 1: 12602, 2: 16681, 3: 24610, 4: 6486}\n",
      "Validation - Loss: 1.4335, Accuracy: 35.54%, Recall: 36.43%, F1-Score: 34.58%\n",
      "Validation loss decreased (inf --> 1.433454).  Saving model ...\n",
      "Train: loss: 1.349839140096623\n",
      "True label distribution: {0: 17802, 1: 15702, 2: 12963, 3: 16998, 4: 6513}\n",
      "Predicted label distribution: {0: 18966, 1: 10073, 2: 20473, 3: 16286, 4: 4180}\n",
      "Validation - Loss: 1.3943, Accuracy: 37.99%, Recall: 38.22%, F1-Score: 36.94%\n",
      "Validation loss decreased (1.433454 --> 1.394331).  Saving model ...\n",
      "Train: loss: 1.3231310883790932\n",
      "True label distribution: {0: 17802, 1: 15702, 2: 12963, 3: 16998, 4: 6513}\n",
      "Predicted label distribution: {0: 19305, 1: 17447, 2: 17160, 3: 11007, 4: 5059}\n",
      "Validation - Loss: 1.4047, Accuracy: 37.47%, Recall: 37.95%, F1-Score: 36.68%\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Train: loss: 1.3029964094501778\n",
      "True label distribution: {0: 17802, 1: 15702, 2: 12963, 3: 16998, 4: 6513}\n",
      "Predicted label distribution: {0: 10161, 1: 17049, 2: 21786, 3: 15195, 4: 5787}\n",
      "Validation - Loss: 1.4015, Accuracy: 37.51%, Recall: 39.08%, F1-Score: 36.01%\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Train: loss: 1.2849137631640064\n",
      "True label distribution: {0: 17802, 1: 15702, 2: 12963, 3: 16998, 4: 6513}\n",
      "Predicted label distribution: {0: 10874, 1: 18976, 2: 18795, 3: 13425, 4: 7908}\n",
      "Validation - Loss: 1.4078, Accuracy: 37.46%, Recall: 39.73%, F1-Score: 36.21%\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Train: loss: 1.2672003920782695\n",
      "True label distribution: {0: 17802, 1: 15702, 2: 12963, 3: 16998, 4: 6513}\n",
      "Predicted label distribution: {0: 11552, 1: 22304, 2: 20971, 3: 9743, 4: 5408}\n",
      "Validation - Loss: 1.4234, Accuracy: 36.35%, Recall: 37.78%, F1-Score: 34.43%\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Train: loss: 1.2509792689516237\n",
      "True label distribution: {0: 17802, 1: 15702, 2: 12963, 3: 16998, 4: 6513}\n",
      "Predicted label distribution: {0: 12838, 1: 18084, 2: 22479, 3: 12181, 4: 4396}\n",
      "Validation - Loss: 1.4156, Accuracy: 37.49%, Recall: 38.34%, F1-Score: 35.99%\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Train: loss: 1.2352750189461266\n",
      "True label distribution: {0: 17802, 1: 15702, 2: 12963, 3: 16998, 4: 6513}\n",
      "Predicted label distribution: {0: 8303, 1: 16897, 2: 19855, 3: 17368, 4: 7555}\n",
      "Validation - Loss: 1.4251, Accuracy: 37.18%, Recall: 39.27%, F1-Score: 35.67%\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Train: loss: 1.220061383365343\n",
      "True label distribution: {0: 17802, 1: 15702, 2: 12963, 3: 16998, 4: 6513}\n",
      "Predicted label distribution: {0: 13611, 1: 18473, 2: 19302, 3: 13176, 4: 5416}\n",
      "Validation - Loss: 1.4175, Accuracy: 37.59%, Recall: 38.48%, F1-Score: 36.55%\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Train: loss: 1.20622606425913\n",
      "True label distribution: {0: 17802, 1: 15702, 2: 12963, 3: 16998, 4: 6513}\n",
      "Predicted label distribution: {0: 9957, 1: 21859, 2: 21501, 3: 11534, 4: 5127}\n",
      "Validation - Loss: 1.4414, Accuracy: 36.99%, Recall: 38.18%, F1-Score: 35.14%\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Train: loss: 1.1919371405277739\n",
      "True label distribution: {0: 17802, 1: 15702, 2: 12963, 3: 16998, 4: 6513}\n",
      "Predicted label distribution: {0: 10368, 1: 18676, 2: 19740, 3: 14999, 4: 6195}\n",
      "Validation - Loss: 1.4353, Accuracy: 37.05%, Recall: 38.44%, F1-Score: 35.76%\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Train: loss: 1.178333629430695\n",
      "True label distribution: {0: 17802, 1: 15702, 2: 12963, 3: 16998, 4: 6513}\n",
      "Predicted label distribution: {0: 9247, 1: 15367, 2: 17550, 3: 17846, 4: 9968}\n",
      "Validation - Loss: 1.4646, Accuracy: 36.37%, Recall: 39.03%, F1-Score: 35.26%\n",
      "EarlyStopping counter: 10 out of 10\n",
      "EarlyStopping counter is higher than patience\n",
      "Early stopping has been reached\n",
      "Starting testing\n",
      "True label distribution: {0: 10212, 1: 14817, 2: 10566, 3: 25503, 4: 14637}\n",
      "Predicted label distribution: {0: 10739, 1: 15082, 2: 12275, 3: 17801, 4: 19838}\n",
      "Test - Loss: 1.4615, Accuracy: 35.47%, Recall: 36.46%, F1-Score: 35.02%\n",
      "Results saved for cnn, iemocap, mspc\n"
     ]
    }
   ],
   "source": [
    "base_args = {\n",
    "    'batch_size': 32,\n",
    "    'epochs': 100,\n",
    "    'lr': 0.0001,\n",
    "    'w_decay': 0.00001,\n",
    "    # Other necessary args for Trainer\n",
    "}\n",
    "\n",
    "# Run combined experiments\n",
    "results_df_icp = run_combined_experiments_icp(base_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e3fb621b-540a-4766-8e13-b245aceca4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Input</th>\n",
       "      <th>Test Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gru</td>\n",
       "      <td>iemocap</td>\n",
       "      <td>mfcc</td>\n",
       "      <td>1.385482</td>\n",
       "      <td>0.405117</td>\n",
       "      <td>0.385303</td>\n",
       "      <td>0.416732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gru</td>\n",
       "      <td>iemocap</td>\n",
       "      <td>mspc</td>\n",
       "      <td>1.481869</td>\n",
       "      <td>0.332026</td>\n",
       "      <td>0.341016</td>\n",
       "      <td>0.364229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cnn</td>\n",
       "      <td>iemocap</td>\n",
       "      <td>mfcc</td>\n",
       "      <td>1.341629</td>\n",
       "      <td>0.410872</td>\n",
       "      <td>0.380301</td>\n",
       "      <td>0.419867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cnn</td>\n",
       "      <td>iemocap</td>\n",
       "      <td>mspc</td>\n",
       "      <td>1.461500</td>\n",
       "      <td>0.354737</td>\n",
       "      <td>0.349820</td>\n",
       "      <td>0.364613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Dataset Input  Test Loss  Accuracy  F1-score    Recall\n",
       "0   gru  iemocap  mfcc   1.385482  0.405117  0.385303  0.416732\n",
       "1   gru  iemocap  mspc   1.481869  0.332026  0.341016  0.364229\n",
       "2   cnn  iemocap  mfcc   1.341629  0.410872  0.380301  0.419867\n",
       "3   cnn  iemocap  mspc   1.461500  0.354737  0.349820  0.364613"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(results_df_icp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd928bb5-c73c-492b-ab40-97bd8f5396c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd71ece-619b-48eb-a848-558a6811987f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
